{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import all necessary libraries\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Table4.csv') # read in the csv file which contains the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Game</th>\n",
       "      <th>Game outcome</th>\n",
       "      <th>Number of top players (In Top 100)</th>\n",
       "      <th>Top scorer (weighted goals) contribution</th>\n",
       "      <th>Top player ratings (total)</th>\n",
       "      <th>Total assists (In Top 100)</th>\n",
       "      <th>Team Versatility score</th>\n",
       "      <th>FIFA 20 rating (sum)</th>\n",
       "      <th>Num top players metric</th>\n",
       "      <th>...</th>\n",
       "      <th>Total assists metric</th>\n",
       "      <th>Team Versatility metric</th>\n",
       "      <th>FIFA 20 rating metric</th>\n",
       "      <th>Ignore</th>\n",
       "      <th>Number of top players (In Top 100).1</th>\n",
       "      <th>Top scorer (weighted goals) contribution.1</th>\n",
       "      <th>Top player ratings (total).1</th>\n",
       "      <th>Total assists (In Top 100).1</th>\n",
       "      <th>Team Versatility score.1</th>\n",
       "      <th>FIFA 20 rating (sum).1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Everton</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>35.68</td>\n",
       "      <td>15</td>\n",
       "      <td>52</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.493499</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leicester</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>49.62</td>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.417722</td>\n",
       "      <td>0.686307</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>42.20</td>\n",
       "      <td>22</td>\n",
       "      <td>64</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.583679</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fulham</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>0.097234</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cardiff</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>20.99</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.290318</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tottenham</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>56.42</td>\n",
       "      <td>28</td>\n",
       "      <td>76</td>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.780360</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chelsea</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>56.92</td>\n",
       "      <td>34</td>\n",
       "      <td>82</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.787275</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Southampton</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>21.02</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.290733</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>34.96</td>\n",
       "      <td>18</td>\n",
       "      <td>79</td>\n",
       "      <td>232</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.483541</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Watford</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>21.24</td>\n",
       "      <td>14</td>\n",
       "      <td>94</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>0.293776</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>West Ham</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>48.87</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.291139</td>\n",
       "      <td>0.675934</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Brighton</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14.01</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.193776</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wolverhampton Wanderers</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>35.26</td>\n",
       "      <td>34</td>\n",
       "      <td>97</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.487690</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>28.65</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.396266</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.097925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Burnley</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>14.14</td>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.195574</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>35.21</td>\n",
       "      <td>22</td>\n",
       "      <td>55</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.486999</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Manchester United</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>35.03</td>\n",
       "      <td>24</td>\n",
       "      <td>43</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.484509</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.949219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Manchester City</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>72.30</td>\n",
       "      <td>57</td>\n",
       "      <td>91</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>71.98</td>\n",
       "      <td>46</td>\n",
       "      <td>100</td>\n",
       "      <td>253</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>28.65</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>232</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.396266</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Watford</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>21.24</td>\n",
       "      <td>14</td>\n",
       "      <td>94</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>0.293776</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Leicester</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>49.62</td>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.417722</td>\n",
       "      <td>0.686307</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Southampton</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>21.02</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.290733</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Brighton</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14.01</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.193776</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>71.98</td>\n",
       "      <td>46</td>\n",
       "      <td>100</td>\n",
       "      <td>253</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Burnley</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>14.14</td>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.195574</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fulham</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>0.097234</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cardiff</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>20.99</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.290318</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.097925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>35.21</td>\n",
       "      <td>22</td>\n",
       "      <td>55</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.486999</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>71.98</td>\n",
       "      <td>46</td>\n",
       "      <td>100</td>\n",
       "      <td>253</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Chelsea</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>56.92</td>\n",
       "      <td>34</td>\n",
       "      <td>82</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.787275</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Watford</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>21.24</td>\n",
       "      <td>14</td>\n",
       "      <td>94</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>0.293776</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.097925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Manchester United</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>35.03</td>\n",
       "      <td>24</td>\n",
       "      <td>43</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.484509</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.949219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>42.20</td>\n",
       "      <td>22</td>\n",
       "      <td>64</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.583679</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Brighton</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14.01</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.193776</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Manchester City</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>72.30</td>\n",
       "      <td>57</td>\n",
       "      <td>91</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Leicester</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>49.62</td>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.417722</td>\n",
       "      <td>0.686307</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Brighton</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14.01</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.193776</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Manchester City</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>72.30</td>\n",
       "      <td>57</td>\n",
       "      <td>91</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Burnley</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>14.14</td>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.195574</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>42.20</td>\n",
       "      <td>22</td>\n",
       "      <td>64</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.583679</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>28.65</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.396266</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>34.96</td>\n",
       "      <td>18</td>\n",
       "      <td>79</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.483541</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Fulham</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>0.097234</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>35.21</td>\n",
       "      <td>22</td>\n",
       "      <td>55</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.486999</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Leicester</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>49.62</td>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.417722</td>\n",
       "      <td>0.686307</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Chelsea</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>56.92</td>\n",
       "      <td>34</td>\n",
       "      <td>82</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.787275</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>71.98</td>\n",
       "      <td>46</td>\n",
       "      <td>100</td>\n",
       "      <td>253</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>253.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Wolverhampton Wanderers</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>35.26</td>\n",
       "      <td>34</td>\n",
       "      <td>97</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.487690</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Manchester United</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>35.03</td>\n",
       "      <td>24</td>\n",
       "      <td>43</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.484509</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.949219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Cardiff</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>20.99</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.290318</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Southampton</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>21.02</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.290733</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.097925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Tottenham</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>56.42</td>\n",
       "      <td>28</td>\n",
       "      <td>76</td>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.780360</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Everton</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>35.68</td>\n",
       "      <td>15</td>\n",
       "      <td>52</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.493499</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Watford</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>21.24</td>\n",
       "      <td>14</td>\n",
       "      <td>94</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>0.293776</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>West Ham</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>48.87</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.291139</td>\n",
       "      <td>0.675934</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team  Game  Game outcome  Number of top players (In Top 100)  \\\n",
       "0         Everton     8             0                                   5   \n",
       "1       Leicester     9             1                                   7   \n",
       "2         Arsenal     5             1                                   6   \n",
       "3          Fulham    19             0                                   1   \n",
       "4         Cardiff    18             0                                   3   \n",
       "..            ...   ...           ...                                 ...   \n",
       "353  Huddersfield    20             1                                   1   \n",
       "354     Tottenham     4             0                                   7   \n",
       "355       Everton     8             1                                   5   \n",
       "356       Watford    11             0                                   3   \n",
       "357      West Ham    10             1                                   7   \n",
       "\n",
       "     Top scorer (weighted goals) contribution  Top player ratings (total)  \\\n",
       "0                                          31                       35.68   \n",
       "1                                          33                       49.62   \n",
       "2                                          48                       42.20   \n",
       "3                                          11                        7.03   \n",
       "4                                           9                       20.99   \n",
       "..                                        ...                         ...   \n",
       "353                                         2                        7.08   \n",
       "354                                        54                       56.42   \n",
       "355                                        31                       35.68   \n",
       "356                                        13                       21.24   \n",
       "357                                        23                       48.87   \n",
       "\n",
       "     Total assists (In Top 100)  Team Versatility score  FIFA 20 rating (sum)  \\\n",
       "0                            15                      52                   235   \n",
       "1                            21                      58                   233   \n",
       "2                            22                      64                   248   \n",
       "3                             3                      70                   220   \n",
       "4                             5                      85                   216   \n",
       "..                          ...                     ...                   ...   \n",
       "353                           0                      67                   215   \n",
       "354                          28                      76                   251   \n",
       "355                          15                      52                   235   \n",
       "356                          14                      94                   233   \n",
       "357                           5                      49                   235   \n",
       "\n",
       "     Num top players metric  ...  Total assists metric  \\\n",
       "0                         0  ...                     0   \n",
       "1                         1  ...                     1   \n",
       "2                         1  ...                     1   \n",
       "3                         0  ...                     0   \n",
       "4                         0  ...                     0   \n",
       "..                      ...  ...                   ...   \n",
       "353                       0  ...                     0   \n",
       "354                       1  ...                     1   \n",
       "355                       0  ...                     0   \n",
       "356                       0  ...                     1   \n",
       "357                       1  ...                     0   \n",
       "\n",
       "     Team Versatility metric  FIFA 20 rating metric  Ignore  \\\n",
       "0                          0                      1    10.0   \n",
       "1                          1                      0    79.0   \n",
       "2                          0                      1    72.3   \n",
       "3                          1                      0    57.0   \n",
       "4                          1                      0   100.0   \n",
       "..                       ...                    ...     ...   \n",
       "353                        1                      0   253.0   \n",
       "354                        1                      1   251.0   \n",
       "355                        0                      0   251.0   \n",
       "356                        1                      0   251.0   \n",
       "357                        0                      1   251.0   \n",
       "\n",
       "     Number of top players (In Top 100).1  \\\n",
       "0                                     0.5   \n",
       "1                                     0.7   \n",
       "2                                     0.6   \n",
       "3                                     0.1   \n",
       "4                                     0.3   \n",
       "..                                    ...   \n",
       "353                                   0.1   \n",
       "354                                   0.7   \n",
       "355                                   0.5   \n",
       "356                                   0.3   \n",
       "357                                   0.7   \n",
       "\n",
       "     Top scorer (weighted goals) contribution.1  Top player ratings (total).1  \\\n",
       "0                                      0.392405                      0.493499   \n",
       "1                                      0.417722                      0.686307   \n",
       "2                                      0.607595                      0.583679   \n",
       "3                                      0.139241                      0.097234   \n",
       "4                                      0.113924                      0.290318   \n",
       "..                                          ...                           ...   \n",
       "353                                    0.025316                      0.097925   \n",
       "354                                    0.683544                      0.780360   \n",
       "355                                    0.392405                      0.493499   \n",
       "356                                    0.164557                      0.293776   \n",
       "357                                    0.291139                      0.675934   \n",
       "\n",
       "     Total assists (In Top 100).1  Team Versatility score.1  \\\n",
       "0                        0.263158                      0.52   \n",
       "1                        0.368421                      0.58   \n",
       "2                        0.385965                      0.64   \n",
       "3                        0.052632                      0.70   \n",
       "4                        0.087719                      0.85   \n",
       "..                            ...                       ...   \n",
       "353                      0.000000                      0.67   \n",
       "354                      0.491228                      0.76   \n",
       "355                      0.263158                      0.52   \n",
       "356                      0.245614                      0.94   \n",
       "357                      0.087719                      0.49   \n",
       "\n",
       "     FIFA 20 rating (sum).1  \n",
       "0                  0.917969  \n",
       "1                  0.910156  \n",
       "2                  0.968750  \n",
       "3                  0.859375  \n",
       "4                  0.843750  \n",
       "..                      ...  \n",
       "353                0.839844  \n",
       "354                0.980469  \n",
       "355                0.917969  \n",
       "356                0.910156  \n",
       "357                0.917969  \n",
       "\n",
       "[358 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # data frame of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of top players (In Top 100).1</th>\n",
       "      <th>Top scorer (weighted goals) contribution.1</th>\n",
       "      <th>Top player ratings (total).1</th>\n",
       "      <th>Total assists (In Top 100).1</th>\n",
       "      <th>Team Versatility score.1</th>\n",
       "      <th>FIFA 20 rating (sum).1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.493499</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.417722</td>\n",
       "      <td>0.686307</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.583679</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>0.097234</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.290318</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.780360</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.787275</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.290733</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.483541</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>0.293776</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.291139</td>\n",
       "      <td>0.675934</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.193776</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.487690</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.396266</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.097925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.195574</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.486999</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.484509</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.949219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.396266</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>0.293776</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.417722</td>\n",
       "      <td>0.686307</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.290733</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.193776</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.195574</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>0.097234</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.290318</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.097925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.486999</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.787275</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>0.293776</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.097925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.484509</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.949219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.583679</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.193776</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.417722</td>\n",
       "      <td>0.686307</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.193776</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.195574</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.583679</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.396266</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.483541</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>0.097234</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.486999</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.417722</td>\n",
       "      <td>0.686307</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.787275</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.487690</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.484509</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.949219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.290318</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.290733</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.097925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.780360</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.493499</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>0.293776</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.291139</td>\n",
       "      <td>0.675934</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number of top players (In Top 100).1  \\\n",
       "0                                     0.5   \n",
       "1                                     0.7   \n",
       "2                                     0.6   \n",
       "3                                     0.1   \n",
       "4                                     0.3   \n",
       "..                                    ...   \n",
       "353                                   0.1   \n",
       "354                                   0.7   \n",
       "355                                   0.5   \n",
       "356                                   0.3   \n",
       "357                                   0.7   \n",
       "\n",
       "     Top scorer (weighted goals) contribution.1  Top player ratings (total).1  \\\n",
       "0                                      0.392405                      0.493499   \n",
       "1                                      0.417722                      0.686307   \n",
       "2                                      0.607595                      0.583679   \n",
       "3                                      0.139241                      0.097234   \n",
       "4                                      0.113924                      0.290318   \n",
       "..                                          ...                           ...   \n",
       "353                                    0.025316                      0.097925   \n",
       "354                                    0.683544                      0.780360   \n",
       "355                                    0.392405                      0.493499   \n",
       "356                                    0.164557                      0.293776   \n",
       "357                                    0.291139                      0.675934   \n",
       "\n",
       "     Total assists (In Top 100).1  Team Versatility score.1  \\\n",
       "0                        0.263158                      0.52   \n",
       "1                        0.368421                      0.58   \n",
       "2                        0.385965                      0.64   \n",
       "3                        0.052632                      0.70   \n",
       "4                        0.087719                      0.85   \n",
       "..                            ...                       ...   \n",
       "353                      0.000000                      0.67   \n",
       "354                      0.491228                      0.76   \n",
       "355                      0.263158                      0.52   \n",
       "356                      0.245614                      0.94   \n",
       "357                      0.087719                      0.49   \n",
       "\n",
       "     FIFA 20 rating (sum).1  \n",
       "0                  0.917969  \n",
       "1                  0.910156  \n",
       "2                  0.968750  \n",
       "3                  0.859375  \n",
       "4                  0.843750  \n",
       "..                      ...  \n",
       "353                0.839844  \n",
       "354                0.980469  \n",
       "355                0.917969  \n",
       "356                0.910156  \n",
       "357                0.917969  \n",
       "\n",
       "[358 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table view of continuous data features\n",
    "X = df.iloc[0:,16:]\n",
    "Y = df.iloc[0:,2]\n",
    "\n",
    "X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, train_size=0.7, random_state = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(6, activation='relu', input_dim=6))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss= 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 108 samples\n",
      "Epoch 1/150\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7375 - acc: 0.4880 - val_loss: 0.7041 - val_acc: 0.5278\n",
      "Epoch 2/150\n",
      "250/250 [==============================] - 0s 118us/step - loss: 0.7114 - acc: 0.4880 - val_loss: 0.6893 - val_acc: 0.5278\n",
      "Epoch 3/150\n",
      "250/250 [==============================] - 0s 131us/step - loss: 0.6933 - acc: 0.5160 - val_loss: 0.6747 - val_acc: 0.6204\n",
      "Epoch 4/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6781 - acc: 0.5760 - val_loss: 0.6688 - val_acc: 0.6389\n",
      "Epoch 5/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.6707 - acc: 0.6040 - val_loss: 0.6668 - val_acc: 0.6204\n",
      "Epoch 6/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6667 - acc: 0.6200 - val_loss: 0.6649 - val_acc: 0.5648\n",
      "Epoch 7/150\n",
      "250/250 [==============================] - 0s 127us/step - loss: 0.6623 - acc: 0.6120 - val_loss: 0.6639 - val_acc: 0.5741\n",
      "Epoch 8/150\n",
      "250/250 [==============================] - 0s 130us/step - loss: 0.6611 - acc: 0.6240 - val_loss: 0.6650 - val_acc: 0.5741\n",
      "Epoch 9/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.6571 - acc: 0.6240 - val_loss: 0.6617 - val_acc: 0.5648\n",
      "Epoch 10/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6543 - acc: 0.6160 - val_loss: 0.6581 - val_acc: 0.5648\n",
      "Epoch 11/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.6530 - acc: 0.6280 - val_loss: 0.6557 - val_acc: 0.5648\n",
      "Epoch 12/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6506 - acc: 0.6240 - val_loss: 0.6568 - val_acc: 0.5648\n",
      "Epoch 13/150\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.6500 - acc: 0.6240 - val_loss: 0.6555 - val_acc: 0.5648\n",
      "Epoch 14/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6484 - acc: 0.6240 - val_loss: 0.6544 - val_acc: 0.5648\n",
      "Epoch 15/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.6473 - acc: 0.6240 - val_loss: 0.6537 - val_acc: 0.5648\n",
      "Epoch 16/150\n",
      "250/250 [==============================] - 0s 223us/step - loss: 0.6471 - acc: 0.6360 - val_loss: 0.6504 - val_acc: 0.6111\n",
      "Epoch 17/150\n",
      "250/250 [==============================] - 0s 130us/step - loss: 0.6453 - acc: 0.6120 - val_loss: 0.6515 - val_acc: 0.5648\n",
      "Epoch 18/150\n",
      "250/250 [==============================] - 0s 134us/step - loss: 0.6448 - acc: 0.6200 - val_loss: 0.6512 - val_acc: 0.5648\n",
      "Epoch 19/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.6442 - acc: 0.6240 - val_loss: 0.6519 - val_acc: 0.5648\n",
      "Epoch 20/150\n",
      "250/250 [==============================] - 0s 130us/step - loss: 0.6432 - acc: 0.6240 - val_loss: 0.6501 - val_acc: 0.5648\n",
      "Epoch 21/150\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.6427 - acc: 0.6200 - val_loss: 0.6485 - val_acc: 0.6111\n",
      "Epoch 22/150\n",
      "250/250 [==============================] - 0s 114us/step - loss: 0.6426 - acc: 0.6160 - val_loss: 0.6482 - val_acc: 0.6111\n",
      "Epoch 23/150\n",
      "250/250 [==============================] - 0s 115us/step - loss: 0.6432 - acc: 0.6240 - val_loss: 0.6482 - val_acc: 0.6111\n",
      "Epoch 24/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6418 - acc: 0.6200 - val_loss: 0.6482 - val_acc: 0.6111\n",
      "Epoch 25/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6417 - acc: 0.6240 - val_loss: 0.6479 - val_acc: 0.6204\n",
      "Epoch 26/150\n",
      "250/250 [==============================] - 0s 113us/step - loss: 0.6438 - acc: 0.6160 - val_loss: 0.6459 - val_acc: 0.6204\n",
      "Epoch 27/150\n",
      "250/250 [==============================] - 0s 112us/step - loss: 0.6428 - acc: 0.6080 - val_loss: 0.6521 - val_acc: 0.5648\n",
      "Epoch 28/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6404 - acc: 0.6240 - val_loss: 0.6480 - val_acc: 0.5648\n",
      "Epoch 29/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6409 - acc: 0.6200 - val_loss: 0.6486 - val_acc: 0.5648\n",
      "Epoch 30/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.6409 - acc: 0.6080 - val_loss: 0.6461 - val_acc: 0.6204\n",
      "Epoch 31/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6398 - acc: 0.6200 - val_loss: 0.6475 - val_acc: 0.6204\n",
      "Epoch 32/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.6399 - acc: 0.6040 - val_loss: 0.6479 - val_acc: 0.5741\n",
      "Epoch 33/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.6398 - acc: 0.6160 - val_loss: 0.6485 - val_acc: 0.5648\n",
      "Epoch 34/150\n",
      "250/250 [==============================] - 0s 114us/step - loss: 0.6402 - acc: 0.6160 - val_loss: 0.6492 - val_acc: 0.5648\n",
      "Epoch 35/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6407 - acc: 0.6280 - val_loss: 0.6469 - val_acc: 0.6204\n",
      "Epoch 36/150\n",
      "250/250 [==============================] - 0s 118us/step - loss: 0.6396 - acc: 0.6160 - val_loss: 0.6477 - val_acc: 0.6204\n",
      "Epoch 37/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.6392 - acc: 0.6320 - val_loss: 0.6494 - val_acc: 0.5648\n",
      "Epoch 38/150\n",
      "250/250 [==============================] - 0s 111us/step - loss: 0.6431 - acc: 0.6240 - val_loss: 0.6493 - val_acc: 0.5648\n",
      "Epoch 39/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.6389 - acc: 0.6200 - val_loss: 0.6498 - val_acc: 0.5648\n",
      "Epoch 40/150\n",
      "250/250 [==============================] - 0s 129us/step - loss: 0.6388 - acc: 0.6040 - val_loss: 0.6490 - val_acc: 0.5741\n",
      "Epoch 41/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.6382 - acc: 0.5960 - val_loss: 0.6488 - val_acc: 0.5741\n",
      "Epoch 42/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6379 - acc: 0.6160 - val_loss: 0.6492 - val_acc: 0.5741\n",
      "Epoch 43/150\n",
      "250/250 [==============================] - 0s 127us/step - loss: 0.6381 - acc: 0.6320 - val_loss: 0.6513 - val_acc: 0.5648\n",
      "Epoch 44/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.6373 - acc: 0.6200 - val_loss: 0.6494 - val_acc: 0.5741\n",
      "Epoch 45/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6372 - acc: 0.6120 - val_loss: 0.6498 - val_acc: 0.5741\n",
      "Epoch 46/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.6371 - acc: 0.6120 - val_loss: 0.6500 - val_acc: 0.5741\n",
      "Epoch 47/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6373 - acc: 0.6200 - val_loss: 0.6500 - val_acc: 0.5741\n",
      "Epoch 48/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.6376 - acc: 0.6080 - val_loss: 0.6494 - val_acc: 0.5741\n",
      "Epoch 49/150\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.6366 - acc: 0.6120 - val_loss: 0.6506 - val_acc: 0.5741\n",
      "Epoch 50/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.6376 - acc: 0.6200 - val_loss: 0.6501 - val_acc: 0.5741\n",
      "Epoch 51/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.6363 - acc: 0.6120 - val_loss: 0.6499 - val_acc: 0.5741\n",
      "Epoch 52/150\n",
      "250/250 [==============================] - 0s 135us/step - loss: 0.6364 - acc: 0.6200 - val_loss: 0.6498 - val_acc: 0.5741\n",
      "Epoch 53/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.6370 - acc: 0.6120 - val_loss: 0.6505 - val_acc: 0.5741\n",
      "Epoch 54/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6375 - acc: 0.6120 - val_loss: 0.6533 - val_acc: 0.5648\n",
      "Epoch 55/150\n",
      "250/250 [==============================] - 0s 127us/step - loss: 0.6379 - acc: 0.6240 - val_loss: 0.6485 - val_acc: 0.6204\n",
      "Epoch 56/150\n",
      "250/250 [==============================] - 0s 118us/step - loss: 0.6372 - acc: 0.6040 - val_loss: 0.6522 - val_acc: 0.5741\n",
      "Epoch 57/150\n",
      "250/250 [==============================] - 0s 134us/step - loss: 0.6373 - acc: 0.6160 - val_loss: 0.6514 - val_acc: 0.5741\n",
      "Epoch 58/150\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.6363 - acc: 0.6160 - val_loss: 0.6493 - val_acc: 0.6204\n",
      "Epoch 59/150\n",
      "250/250 [==============================] - 0s 130us/step - loss: 0.6360 - acc: 0.6160 - val_loss: 0.6521 - val_acc: 0.5741\n",
      "Epoch 60/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.6359 - acc: 0.6200 - val_loss: 0.6512 - val_acc: 0.5741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "250/250 [==============================] - 0s 131us/step - loss: 0.6360 - acc: 0.6120 - val_loss: 0.6505 - val_acc: 0.5741\n",
      "Epoch 62/150\n",
      "250/250 [==============================] - 0s 111us/step - loss: 0.6377 - acc: 0.6160 - val_loss: 0.6530 - val_acc: 0.5741\n",
      "Epoch 63/150\n",
      "250/250 [==============================] - 0s 113us/step - loss: 0.6373 - acc: 0.6160 - val_loss: 0.6501 - val_acc: 0.6204\n",
      "Epoch 64/150\n",
      "250/250 [==============================] - 0s 130us/step - loss: 0.6361 - acc: 0.6160 - val_loss: 0.6509 - val_acc: 0.5741\n",
      "Epoch 65/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6386 - acc: 0.6040 - val_loss: 0.6543 - val_acc: 0.5648\n",
      "Epoch 66/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6353 - acc: 0.6200 - val_loss: 0.6518 - val_acc: 0.5741\n",
      "Epoch 67/150\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.6348 - acc: 0.6200 - val_loss: 0.6506 - val_acc: 0.6204\n",
      "Epoch 68/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.6353 - acc: 0.6160 - val_loss: 0.6510 - val_acc: 0.5741\n",
      "Epoch 69/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6359 - acc: 0.6200 - val_loss: 0.6515 - val_acc: 0.5741\n",
      "Epoch 70/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6361 - acc: 0.6120 - val_loss: 0.6540 - val_acc: 0.5741\n",
      "Epoch 71/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.6360 - acc: 0.6120 - val_loss: 0.6533 - val_acc: 0.5741\n",
      "Epoch 72/150\n",
      "250/250 [==============================] - 0s 137us/step - loss: 0.6361 - acc: 0.6240 - val_loss: 0.6533 - val_acc: 0.5741\n",
      "Epoch 73/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.6358 - acc: 0.6120 - val_loss: 0.6512 - val_acc: 0.6204\n",
      "Epoch 74/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6354 - acc: 0.6200 - val_loss: 0.6538 - val_acc: 0.5741\n",
      "Epoch 75/150\n",
      "250/250 [==============================] - 0s 127us/step - loss: 0.6353 - acc: 0.6120 - val_loss: 0.6533 - val_acc: 0.5741\n",
      "Epoch 76/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6360 - acc: 0.6080 - val_loss: 0.6548 - val_acc: 0.5741\n",
      "Epoch 77/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.6366 - acc: 0.6240 - val_loss: 0.6516 - val_acc: 0.6204\n",
      "Epoch 78/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6354 - acc: 0.6240 - val_loss: 0.6545 - val_acc: 0.5741\n",
      "Epoch 79/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6349 - acc: 0.6120 - val_loss: 0.6527 - val_acc: 0.5741\n",
      "Epoch 80/150\n",
      "250/250 [==============================] - 0s 115us/step - loss: 0.6363 - acc: 0.6120 - val_loss: 0.6547 - val_acc: 0.5741\n",
      "Epoch 81/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6349 - acc: 0.6040 - val_loss: 0.6523 - val_acc: 0.6204\n",
      "Epoch 82/150\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.6356 - acc: 0.6160 - val_loss: 0.6527 - val_acc: 0.6204\n",
      "Epoch 83/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6355 - acc: 0.6160 - val_loss: 0.6580 - val_acc: 0.5648\n",
      "Epoch 84/150\n",
      "250/250 [==============================] - 0s 175us/step - loss: 0.6348 - acc: 0.6120 - val_loss: 0.6535 - val_acc: 0.5741\n",
      "Epoch 85/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.6347 - acc: 0.6120 - val_loss: 0.6542 - val_acc: 0.5741\n",
      "Epoch 86/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6347 - acc: 0.6040 - val_loss: 0.6533 - val_acc: 0.5741\n",
      "Epoch 87/150\n",
      "250/250 [==============================] - 0s 143us/step - loss: 0.6348 - acc: 0.6160 - val_loss: 0.6548 - val_acc: 0.5741\n",
      "Epoch 88/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6354 - acc: 0.6120 - val_loss: 0.6546 - val_acc: 0.5741\n",
      "Epoch 89/150\n",
      "250/250 [==============================] - 0s 114us/step - loss: 0.6353 - acc: 0.6200 - val_loss: 0.6531 - val_acc: 0.6204\n",
      "Epoch 90/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.6344 - acc: 0.6080 - val_loss: 0.6550 - val_acc: 0.5741\n",
      "Epoch 91/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.6352 - acc: 0.6120 - val_loss: 0.6548 - val_acc: 0.5741\n",
      "Epoch 92/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6352 - acc: 0.6080 - val_loss: 0.6546 - val_acc: 0.5741\n",
      "Epoch 93/150\n",
      "250/250 [==============================] - 0s 127us/step - loss: 0.6345 - acc: 0.6120 - val_loss: 0.6554 - val_acc: 0.5741\n",
      "Epoch 94/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6346 - acc: 0.6120 - val_loss: 0.6555 - val_acc: 0.5741\n",
      "Epoch 95/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6347 - acc: 0.6120 - val_loss: 0.6555 - val_acc: 0.5741\n",
      "Epoch 96/150\n",
      "250/250 [==============================] - 0s 112us/step - loss: 0.6366 - acc: 0.6120 - val_loss: 0.6571 - val_acc: 0.5741\n",
      "Epoch 97/150\n",
      "250/250 [==============================] - 0s 142us/step - loss: 0.6344 - acc: 0.6120 - val_loss: 0.6545 - val_acc: 0.5741\n",
      "Epoch 98/150\n",
      "250/250 [==============================] - 0s 109us/step - loss: 0.6348 - acc: 0.6120 - val_loss: 0.6548 - val_acc: 0.5741\n",
      "Epoch 99/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.6349 - acc: 0.6120 - val_loss: 0.6573 - val_acc: 0.5741\n",
      "Epoch 100/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6342 - acc: 0.6120 - val_loss: 0.6561 - val_acc: 0.5741\n",
      "Epoch 101/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.6352 - acc: 0.6000 - val_loss: 0.6557 - val_acc: 0.5741\n",
      "Epoch 102/150\n",
      "250/250 [==============================] - 0s 112us/step - loss: 0.6377 - acc: 0.6160 - val_loss: 0.6554 - val_acc: 0.5741\n",
      "Epoch 103/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.6346 - acc: 0.6120 - val_loss: 0.6569 - val_acc: 0.5741\n",
      "Epoch 104/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.6358 - acc: 0.6120 - val_loss: 0.6570 - val_acc: 0.5741\n",
      "Epoch 105/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6356 - acc: 0.6120 - val_loss: 0.6570 - val_acc: 0.5741\n",
      "Epoch 106/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6350 - acc: 0.6120 - val_loss: 0.6571 - val_acc: 0.5741\n",
      "Epoch 107/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.6355 - acc: 0.6160 - val_loss: 0.6567 - val_acc: 0.5741\n",
      "Epoch 108/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.6353 - acc: 0.6120 - val_loss: 0.6584 - val_acc: 0.5741\n",
      "Epoch 109/150\n",
      "250/250 [==============================] - 0s 130us/step - loss: 0.6343 - acc: 0.6120 - val_loss: 0.6557 - val_acc: 0.5741\n",
      "Epoch 110/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6343 - acc: 0.6040 - val_loss: 0.6554 - val_acc: 0.6204\n",
      "Epoch 111/150\n",
      "250/250 [==============================] - 0s 130us/step - loss: 0.6341 - acc: 0.6120 - val_loss: 0.6568 - val_acc: 0.5741\n",
      "Epoch 112/150\n",
      "250/250 [==============================] - 0s 127us/step - loss: 0.6340 - acc: 0.6120 - val_loss: 0.6579 - val_acc: 0.5741\n",
      "Epoch 113/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.6351 - acc: 0.6120 - val_loss: 0.6569 - val_acc: 0.5741\n",
      "Epoch 114/150\n",
      "250/250 [==============================] - 0s 127us/step - loss: 0.6350 - acc: 0.6120 - val_loss: 0.6578 - val_acc: 0.5741\n",
      "Epoch 115/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6343 - acc: 0.6120 - val_loss: 0.6573 - val_acc: 0.5741\n",
      "Epoch 116/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.6352 - acc: 0.6040 - val_loss: 0.6582 - val_acc: 0.5741\n",
      "Epoch 117/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.6345 - acc: 0.6120 - val_loss: 0.6580 - val_acc: 0.5741\n",
      "Epoch 118/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.6344 - acc: 0.6120 - val_loss: 0.6578 - val_acc: 0.5741\n",
      "Epoch 119/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.6354 - acc: 0.6160 - val_loss: 0.6572 - val_acc: 0.5741\n",
      "Epoch 120/150\n",
      "250/250 [==============================] - 0s 138us/step - loss: 0.6346 - acc: 0.6120 - val_loss: 0.6574 - val_acc: 0.5741\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 128us/step - loss: 0.6341 - acc: 0.6120 - val_loss: 0.6579 - val_acc: 0.5741\n",
      "Epoch 122/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6352 - acc: 0.6120 - val_loss: 0.6593 - val_acc: 0.5741\n",
      "Epoch 123/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6362 - acc: 0.6040 - val_loss: 0.6587 - val_acc: 0.5741\n",
      "Epoch 124/150\n",
      "250/250 [==============================] - 0s 114us/step - loss: 0.6347 - acc: 0.6080 - val_loss: 0.6575 - val_acc: 0.5741\n",
      "Epoch 125/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6345 - acc: 0.6120 - val_loss: 0.6590 - val_acc: 0.5741\n",
      "Epoch 126/150\n",
      "250/250 [==============================] - 0s 112us/step - loss: 0.6341 - acc: 0.6120 - val_loss: 0.6587 - val_acc: 0.5741\n",
      "Epoch 127/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.6347 - acc: 0.6120 - val_loss: 0.6588 - val_acc: 0.5741\n",
      "Epoch 128/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6341 - acc: 0.6120 - val_loss: 0.6587 - val_acc: 0.5741\n",
      "Epoch 129/150\n",
      "250/250 [==============================] - 0s 134us/step - loss: 0.6340 - acc: 0.6120 - val_loss: 0.6579 - val_acc: 0.5741\n",
      "Epoch 130/150\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.6340 - acc: 0.6120 - val_loss: 0.6593 - val_acc: 0.5741\n",
      "Epoch 131/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6339 - acc: 0.6120 - val_loss: 0.6582 - val_acc: 0.5741\n",
      "Epoch 132/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6342 - acc: 0.6120 - val_loss: 0.6580 - val_acc: 0.5741\n",
      "Epoch 133/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6348 - acc: 0.6120 - val_loss: 0.6589 - val_acc: 0.5741\n",
      "Epoch 134/150\n",
      "250/250 [==============================] - 0s 118us/step - loss: 0.6335 - acc: 0.6120 - val_loss: 0.6580 - val_acc: 0.5741\n",
      "Epoch 135/150\n",
      "250/250 [==============================] - 0s 131us/step - loss: 0.6355 - acc: 0.6120 - val_loss: 0.6589 - val_acc: 0.5741\n",
      "Epoch 136/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.6344 - acc: 0.6120 - val_loss: 0.6579 - val_acc: 0.5741\n",
      "Epoch 137/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6350 - acc: 0.6160 - val_loss: 0.6574 - val_acc: 0.6204\n",
      "Epoch 138/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.6338 - acc: 0.6120 - val_loss: 0.6598 - val_acc: 0.5741\n",
      "Epoch 139/150\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.6349 - acc: 0.6120 - val_loss: 0.6588 - val_acc: 0.5741\n",
      "Epoch 140/150\n",
      "250/250 [==============================] - 0s 113us/step - loss: 0.6342 - acc: 0.6120 - val_loss: 0.6593 - val_acc: 0.5741\n",
      "Epoch 141/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6340 - acc: 0.6120 - val_loss: 0.6597 - val_acc: 0.5741\n",
      "Epoch 142/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6372 - acc: 0.6160 - val_loss: 0.6582 - val_acc: 0.5741\n",
      "Epoch 143/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.6352 - acc: 0.6120 - val_loss: 0.6618 - val_acc: 0.5741\n",
      "Epoch 144/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6345 - acc: 0.6120 - val_loss: 0.6583 - val_acc: 0.5741\n",
      "Epoch 145/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6355 - acc: 0.6120 - val_loss: 0.6589 - val_acc: 0.5741\n",
      "Epoch 146/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6341 - acc: 0.6120 - val_loss: 0.6592 - val_acc: 0.5741\n",
      "Epoch 147/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.6344 - acc: 0.6120 - val_loss: 0.6590 - val_acc: 0.5741\n",
      "Epoch 148/150\n",
      "250/250 [==============================] - 0s 111us/step - loss: 0.6347 - acc: 0.6120 - val_loss: 0.6613 - val_acc: 0.5741\n",
      "Epoch 149/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6338 - acc: 0.6120 - val_loss: 0.6598 - val_acc: 0.5741\n",
      "Epoch 150/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.6345 - acc: 0.6120 - val_loss: 0.6596 - val_acc: 0.5741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2a89d1d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=10, epochs=150, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6168147071644112\n"
     ]
    }
   ],
   "source": [
    "#Results after running the input data that has\n",
    "# not been binary encoded through the deep neural network.\n",
    "# roundn encodes each value in the array as 0 or 1\n",
    "# \n",
    "def roundn(x):\n",
    "    for i in range(0,len(x)):\n",
    "        \n",
    "        if (i<0.5):\n",
    "            i = 0\n",
    "        else:\n",
    "            i = 1\n",
    "    return x\n",
    "y_predict = roundn(model.predict(X_test))\n",
    "y_predict = (y_predict)\n",
    "len(y_predict)\n",
    "\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33, 24],\n",
       "       [22, 29]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix on the input data features\n",
    "# that have not yet been encoded as binary values\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "y_predict = np.where(y_predict > 0.5, 1, 0)\n",
    "cm = confusion_matrix(Y_test, y_predict)\n",
    "cm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num top players metric</th>\n",
       "      <th>Top scorer metric</th>\n",
       "      <th>Top player ratings metric</th>\n",
       "      <th>Total assists metric</th>\n",
       "      <th>Team Versatility metric</th>\n",
       "      <th>FIFA 20 rating metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Num top players metric  Top scorer metric  Top player ratings metric  \\\n",
       "0                         0                  0                          0   \n",
       "1                         1                  1                          1   \n",
       "2                         1                  1                          1   \n",
       "3                         0                  0                          0   \n",
       "4                         0                  0                          0   \n",
       "..                      ...                ...                        ...   \n",
       "353                       0                  0                          0   \n",
       "354                       1                  1                          1   \n",
       "355                       0                  0                          0   \n",
       "356                       0                  0                          0   \n",
       "357                       1                  1                          1   \n",
       "\n",
       "     Total assists metric  Team Versatility metric  FIFA 20 rating metric  \n",
       "0                       0                        0                      1  \n",
       "1                       1                        1                      0  \n",
       "2                       1                        0                      1  \n",
       "3                       0                        1                      0  \n",
       "4                       0                        1                      0  \n",
       "..                    ...                      ...                    ...  \n",
       "353                     0                        1                      0  \n",
       "354                     1                        1                      1  \n",
       "355                     0                        0                      0  \n",
       "356                     1                        1                      0  \n",
       "357                     0                        0                      1  \n",
       "\n",
       "[358 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features of binary encoded data features\n",
    "X_1 = df.iloc[0:,9:15]\n",
    "Y_1 = df.iloc[0:,2]\n",
    "\n",
    "X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, Y_train_1, Y_test_1 = train_test_split(X_1,Y_1, train_size=0.7, random_state = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(6, activation='relu', input_dim=6))\n",
    "model_1.add(Dense(6, activation='relu'))\n",
    "model_1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model_1.compile(loss= 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 108 samples\n",
      "Epoch 1/150\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6619 - acc: 0.5880 - val_loss: 0.6828 - val_acc: 0.5833\n",
      "Epoch 2/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.6516 - acc: 0.5920 - val_loss: 0.6823 - val_acc: 0.6111\n",
      "Epoch 3/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.6465 - acc: 0.6960 - val_loss: 0.6816 - val_acc: 0.6111\n",
      "Epoch 4/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6432 - acc: 0.6960 - val_loss: 0.6825 - val_acc: 0.6019\n",
      "Epoch 5/150\n",
      "250/250 [==============================] - 0s 129us/step - loss: 0.6416 - acc: 0.6880 - val_loss: 0.6823 - val_acc: 0.6019\n",
      "Epoch 6/150\n",
      "250/250 [==============================] - 0s 127us/step - loss: 0.6392 - acc: 0.6880 - val_loss: 0.6814 - val_acc: 0.6019\n",
      "Epoch 7/150\n",
      "250/250 [==============================] - 0s 131us/step - loss: 0.6371 - acc: 0.6880 - val_loss: 0.6803 - val_acc: 0.6019\n",
      "Epoch 8/150\n",
      "250/250 [==============================] - 0s 129us/step - loss: 0.6339 - acc: 0.6920 - val_loss: 0.6784 - val_acc: 0.6111\n",
      "Epoch 9/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.6304 - acc: 0.6960 - val_loss: 0.6783 - val_acc: 0.6111\n",
      "Epoch 10/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.6277 - acc: 0.6920 - val_loss: 0.6761 - val_acc: 0.6204\n",
      "Epoch 11/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.6250 - acc: 0.6960 - val_loss: 0.6748 - val_acc: 0.6204\n",
      "Epoch 12/150\n",
      "250/250 [==============================] - 0s 118us/step - loss: 0.6232 - acc: 0.6960 - val_loss: 0.6749 - val_acc: 0.6204\n",
      "Epoch 13/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.6206 - acc: 0.6960 - val_loss: 0.6731 - val_acc: 0.6204\n",
      "Epoch 14/150\n",
      "250/250 [==============================] - 0s 225us/step - loss: 0.6202 - acc: 0.6960 - val_loss: 0.6700 - val_acc: 0.6204\n",
      "Epoch 15/150\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.6171 - acc: 0.6960 - val_loss: 0.6715 - val_acc: 0.6204\n",
      "Epoch 16/150\n",
      "250/250 [==============================] - 0s 131us/step - loss: 0.6165 - acc: 0.6960 - val_loss: 0.6690 - val_acc: 0.6296\n",
      "Epoch 17/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6150 - acc: 0.6960 - val_loss: 0.6697 - val_acc: 0.6296\n",
      "Epoch 18/150\n",
      "250/250 [==============================] - 0s 132us/step - loss: 0.6130 - acc: 0.6960 - val_loss: 0.6679 - val_acc: 0.6296\n",
      "Epoch 19/150\n",
      "250/250 [==============================] - 0s 131us/step - loss: 0.6115 - acc: 0.6960 - val_loss: 0.6697 - val_acc: 0.6296\n",
      "Epoch 20/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.6110 - acc: 0.6960 - val_loss: 0.6678 - val_acc: 0.6296\n",
      "Epoch 21/150\n",
      "250/250 [==============================] - 0s 127us/step - loss: 0.6101 - acc: 0.6960 - val_loss: 0.6676 - val_acc: 0.6296\n",
      "Epoch 22/150\n",
      "250/250 [==============================] - 0s 129us/step - loss: 0.6091 - acc: 0.7040 - val_loss: 0.6632 - val_acc: 0.6389\n",
      "Epoch 23/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.6077 - acc: 0.7080 - val_loss: 0.6677 - val_acc: 0.6389\n",
      "Epoch 24/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6071 - acc: 0.7080 - val_loss: 0.6666 - val_acc: 0.6389\n",
      "Epoch 25/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.6060 - acc: 0.7040 - val_loss: 0.6658 - val_acc: 0.6389\n",
      "Epoch 26/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.6054 - acc: 0.7040 - val_loss: 0.6667 - val_acc: 0.6389\n",
      "Epoch 27/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6046 - acc: 0.7040 - val_loss: 0.6649 - val_acc: 0.6389\n",
      "Epoch 28/150\n",
      "250/250 [==============================] - 0s 118us/step - loss: 0.6041 - acc: 0.7040 - val_loss: 0.6654 - val_acc: 0.6389\n",
      "Epoch 29/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.6034 - acc: 0.7040 - val_loss: 0.6656 - val_acc: 0.6389\n",
      "Epoch 30/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.6034 - acc: 0.7080 - val_loss: 0.6638 - val_acc: 0.6481\n",
      "Epoch 31/150\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.6035 - acc: 0.7080 - val_loss: 0.6657 - val_acc: 0.6481\n",
      "Epoch 32/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.6020 - acc: 0.7080 - val_loss: 0.6657 - val_acc: 0.6481\n",
      "Epoch 33/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.6016 - acc: 0.7080 - val_loss: 0.6656 - val_acc: 0.6481\n",
      "Epoch 34/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.6019 - acc: 0.7040 - val_loss: 0.6663 - val_acc: 0.6481\n",
      "Epoch 35/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.6012 - acc: 0.7040 - val_loss: 0.6662 - val_acc: 0.6481\n",
      "Epoch 36/150\n",
      "250/250 [==============================] - 0s 109us/step - loss: 0.6006 - acc: 0.7080 - val_loss: 0.6671 - val_acc: 0.6481\n",
      "Epoch 37/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.6002 - acc: 0.7080 - val_loss: 0.6654 - val_acc: 0.6481\n",
      "Epoch 38/150\n",
      "250/250 [==============================] - 0s 115us/step - loss: 0.6005 - acc: 0.7040 - val_loss: 0.6679 - val_acc: 0.6481\n",
      "Epoch 39/150\n",
      "250/250 [==============================] - 0s 115us/step - loss: 0.5999 - acc: 0.7000 - val_loss: 0.6634 - val_acc: 0.6481\n",
      "Epoch 40/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.5998 - acc: 0.7080 - val_loss: 0.6671 - val_acc: 0.6481\n",
      "Epoch 41/150\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.5991 - acc: 0.7080 - val_loss: 0.6664 - val_acc: 0.6481\n",
      "Epoch 42/150\n",
      "250/250 [==============================] - 0s 115us/step - loss: 0.5993 - acc: 0.7080 - val_loss: 0.6663 - val_acc: 0.6481\n",
      "Epoch 43/150\n",
      "250/250 [==============================] - 0s 129us/step - loss: 0.5990 - acc: 0.7080 - val_loss: 0.6655 - val_acc: 0.6481\n",
      "Epoch 44/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.5982 - acc: 0.7080 - val_loss: 0.6657 - val_acc: 0.6481\n",
      "Epoch 45/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.5985 - acc: 0.7120 - val_loss: 0.6650 - val_acc: 0.6481\n",
      "Epoch 46/150\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.5981 - acc: 0.7120 - val_loss: 0.6666 - val_acc: 0.6481\n",
      "Epoch 47/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.5977 - acc: 0.7080 - val_loss: 0.6675 - val_acc: 0.6481\n",
      "Epoch 48/150\n",
      "250/250 [==============================] - 0s 118us/step - loss: 0.5980 - acc: 0.7040 - val_loss: 0.6657 - val_acc: 0.6481\n",
      "Epoch 49/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.5975 - acc: 0.7040 - val_loss: 0.6653 - val_acc: 0.6481\n",
      "Epoch 50/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.5978 - acc: 0.7080 - val_loss: 0.6679 - val_acc: 0.6481\n",
      "Epoch 51/150\n",
      "250/250 [==============================] - 0s 108us/step - loss: 0.5970 - acc: 0.7000 - val_loss: 0.6679 - val_acc: 0.6481\n",
      "Epoch 52/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.5983 - acc: 0.7040 - val_loss: 0.6653 - val_acc: 0.6481\n",
      "Epoch 53/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.5968 - acc: 0.7040 - val_loss: 0.6646 - val_acc: 0.6481\n",
      "Epoch 54/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.5969 - acc: 0.7040 - val_loss: 0.6670 - val_acc: 0.6481\n",
      "Epoch 55/150\n",
      "250/250 [==============================] - 0s 118us/step - loss: 0.5968 - acc: 0.7040 - val_loss: 0.6653 - val_acc: 0.6481\n",
      "Epoch 56/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.5981 - acc: 0.7040 - val_loss: 0.6642 - val_acc: 0.6481\n",
      "Epoch 57/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.5970 - acc: 0.7000 - val_loss: 0.6689 - val_acc: 0.6481\n",
      "Epoch 58/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.5962 - acc: 0.7040 - val_loss: 0.6658 - val_acc: 0.6481\n",
      "Epoch 59/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.5974 - acc: 0.7040 - val_loss: 0.6662 - val_acc: 0.6481\n",
      "Epoch 60/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.5961 - acc: 0.7000 - val_loss: 0.6674 - val_acc: 0.6574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "250/250 [==============================] - 0s 129us/step - loss: 0.5957 - acc: 0.7040 - val_loss: 0.6682 - val_acc: 0.6574\n",
      "Epoch 62/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.5969 - acc: 0.7040 - val_loss: 0.6688 - val_acc: 0.6574\n",
      "Epoch 63/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.5954 - acc: 0.7040 - val_loss: 0.6649 - val_acc: 0.6481\n",
      "Epoch 64/150\n",
      "250/250 [==============================] - 0s 115us/step - loss: 0.5953 - acc: 0.7040 - val_loss: 0.6666 - val_acc: 0.6574\n",
      "Epoch 65/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.5955 - acc: 0.7040 - val_loss: 0.6652 - val_acc: 0.6574\n",
      "Epoch 66/150\n",
      "250/250 [==============================] - 0s 127us/step - loss: 0.5949 - acc: 0.7040 - val_loss: 0.6678 - val_acc: 0.6574\n",
      "Epoch 67/150\n",
      "250/250 [==============================] - 0s 141us/step - loss: 0.5952 - acc: 0.7040 - val_loss: 0.6664 - val_acc: 0.6574\n",
      "Epoch 68/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.5949 - acc: 0.7040 - val_loss: 0.6665 - val_acc: 0.6574\n",
      "Epoch 69/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.5952 - acc: 0.7040 - val_loss: 0.6666 - val_acc: 0.6574\n",
      "Epoch 70/150\n",
      "250/250 [==============================] - 0s 127us/step - loss: 0.5947 - acc: 0.7040 - val_loss: 0.6676 - val_acc: 0.6574\n",
      "Epoch 71/150\n",
      "250/250 [==============================] - 0s 137us/step - loss: 0.5945 - acc: 0.7040 - val_loss: 0.6668 - val_acc: 0.6574\n",
      "Epoch 72/150\n",
      "250/250 [==============================] - 0s 127us/step - loss: 0.5943 - acc: 0.7040 - val_loss: 0.6662 - val_acc: 0.6574\n",
      "Epoch 73/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.5947 - acc: 0.7040 - val_loss: 0.6666 - val_acc: 0.6574\n",
      "Epoch 74/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.5942 - acc: 0.7040 - val_loss: 0.6672 - val_acc: 0.6574\n",
      "Epoch 75/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.5949 - acc: 0.7040 - val_loss: 0.6655 - val_acc: 0.6574\n",
      "Epoch 76/150\n",
      "250/250 [==============================] - 0s 128us/step - loss: 0.5947 - acc: 0.7040 - val_loss: 0.6677 - val_acc: 0.6574\n",
      "Epoch 77/150\n",
      "250/250 [==============================] - 0s 131us/step - loss: 0.5950 - acc: 0.7040 - val_loss: 0.6644 - val_acc: 0.6574\n",
      "Epoch 78/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.5949 - acc: 0.7040 - val_loss: 0.6684 - val_acc: 0.6574\n",
      "Epoch 79/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.5942 - acc: 0.7040 - val_loss: 0.6659 - val_acc: 0.6574\n",
      "Epoch 80/150\n",
      "250/250 [==============================] - 0s 110us/step - loss: 0.5935 - acc: 0.7040 - val_loss: 0.6679 - val_acc: 0.6574\n",
      "Epoch 81/150\n",
      "250/250 [==============================] - 0s 115us/step - loss: 0.5949 - acc: 0.7000 - val_loss: 0.6704 - val_acc: 0.6574\n",
      "Epoch 82/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.5939 - acc: 0.7040 - val_loss: 0.6646 - val_acc: 0.6574\n",
      "Epoch 83/150\n",
      "250/250 [==============================] - 0s 134us/step - loss: 0.5935 - acc: 0.7040 - val_loss: 0.6674 - val_acc: 0.6574\n",
      "Epoch 84/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.5933 - acc: 0.7040 - val_loss: 0.6665 - val_acc: 0.6574\n",
      "Epoch 85/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.5937 - acc: 0.7040 - val_loss: 0.6677 - val_acc: 0.6574\n",
      "Epoch 86/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.5933 - acc: 0.7040 - val_loss: 0.6668 - val_acc: 0.6574\n",
      "Epoch 87/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.5931 - acc: 0.7040 - val_loss: 0.6672 - val_acc: 0.6574\n",
      "Epoch 88/150\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.5926 - acc: 0.7040 - val_loss: 0.6675 - val_acc: 0.6574\n",
      "Epoch 89/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.5929 - acc: 0.7080 - val_loss: 0.6685 - val_acc: 0.6574\n",
      "Epoch 90/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.5934 - acc: 0.7040 - val_loss: 0.6661 - val_acc: 0.6574\n",
      "Epoch 91/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.5925 - acc: 0.7040 - val_loss: 0.6670 - val_acc: 0.6574\n",
      "Epoch 92/150\n",
      "250/250 [==============================] - 0s 115us/step - loss: 0.5932 - acc: 0.7040 - val_loss: 0.6697 - val_acc: 0.6574\n",
      "Epoch 93/150\n",
      "250/250 [==============================] - 0s 115us/step - loss: 0.5924 - acc: 0.7080 - val_loss: 0.6677 - val_acc: 0.6574\n",
      "Epoch 94/150\n",
      "250/250 [==============================] - 0s 118us/step - loss: 0.5926 - acc: 0.7040 - val_loss: 0.6681 - val_acc: 0.6574\n",
      "Epoch 95/150\n",
      "250/250 [==============================] - 0s 114us/step - loss: 0.5925 - acc: 0.7040 - val_loss: 0.6668 - val_acc: 0.6574\n",
      "Epoch 96/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.5922 - acc: 0.7000 - val_loss: 0.6686 - val_acc: 0.6574\n",
      "Epoch 97/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.5929 - acc: 0.7040 - val_loss: 0.6703 - val_acc: 0.6574\n",
      "Epoch 98/150\n",
      "250/250 [==============================] - 0s 135us/step - loss: 0.5919 - acc: 0.7120 - val_loss: 0.6672 - val_acc: 0.6574\n",
      "Epoch 99/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.5928 - acc: 0.7000 - val_loss: 0.6677 - val_acc: 0.6574\n",
      "Epoch 100/150\n",
      "250/250 [==============================] - 0s 112us/step - loss: 0.5926 - acc: 0.7000 - val_loss: 0.6681 - val_acc: 0.6574\n",
      "Epoch 101/150\n",
      "250/250 [==============================] - 0s 125us/step - loss: 0.5921 - acc: 0.7040 - val_loss: 0.6697 - val_acc: 0.6574\n",
      "Epoch 102/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.5915 - acc: 0.7040 - val_loss: 0.6682 - val_acc: 0.6574\n",
      "Epoch 103/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.5922 - acc: 0.7040 - val_loss: 0.6669 - val_acc: 0.6574\n",
      "Epoch 104/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.5922 - acc: 0.7000 - val_loss: 0.6676 - val_acc: 0.6574\n",
      "Epoch 105/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.5929 - acc: 0.7080 - val_loss: 0.6672 - val_acc: 0.6574\n",
      "Epoch 106/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.5925 - acc: 0.7040 - val_loss: 0.6709 - val_acc: 0.6574\n",
      "Epoch 107/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.5936 - acc: 0.7080 - val_loss: 0.6675 - val_acc: 0.6574\n",
      "Epoch 108/150\n",
      "250/250 [==============================] - 0s 118us/step - loss: 0.5910 - acc: 0.7040 - val_loss: 0.6693 - val_acc: 0.6574\n",
      "Epoch 109/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.5913 - acc: 0.7040 - val_loss: 0.6699 - val_acc: 0.6574\n",
      "Epoch 110/150\n",
      "250/250 [==============================] - 0s 115us/step - loss: 0.5913 - acc: 0.7040 - val_loss: 0.6676 - val_acc: 0.6574\n",
      "Epoch 111/150\n",
      "250/250 [==============================] - 0s 111us/step - loss: 0.5916 - acc: 0.7040 - val_loss: 0.6700 - val_acc: 0.6574\n",
      "Epoch 112/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.5913 - acc: 0.7040 - val_loss: 0.6672 - val_acc: 0.6574\n",
      "Epoch 113/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.5919 - acc: 0.7040 - val_loss: 0.6705 - val_acc: 0.6574\n",
      "Epoch 114/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.5912 - acc: 0.7040 - val_loss: 0.6684 - val_acc: 0.6574\n",
      "Epoch 115/150\n",
      "250/250 [==============================] - 0s 114us/step - loss: 0.5910 - acc: 0.7040 - val_loss: 0.6706 - val_acc: 0.6574\n",
      "Epoch 116/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.5905 - acc: 0.7040 - val_loss: 0.6685 - val_acc: 0.6574\n",
      "Epoch 117/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.5910 - acc: 0.7040 - val_loss: 0.6680 - val_acc: 0.6574\n",
      "Epoch 118/150\n",
      "250/250 [==============================] - 0s 121us/step - loss: 0.5909 - acc: 0.7040 - val_loss: 0.6698 - val_acc: 0.6574\n",
      "Epoch 119/150\n",
      "250/250 [==============================] - 0s 129us/step - loss: 0.5902 - acc: 0.7040 - val_loss: 0.6728 - val_acc: 0.6574\n",
      "Epoch 120/150\n",
      "250/250 [==============================] - 0s 118us/step - loss: 0.5903 - acc: 0.7040 - val_loss: 0.6713 - val_acc: 0.6574\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 122us/step - loss: 0.5900 - acc: 0.7040 - val_loss: 0.6718 - val_acc: 0.6574\n",
      "Epoch 122/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.5906 - acc: 0.7040 - val_loss: 0.6736 - val_acc: 0.6574\n",
      "Epoch 123/150\n",
      "250/250 [==============================] - 0s 114us/step - loss: 0.5922 - acc: 0.7040 - val_loss: 0.6698 - val_acc: 0.6574\n",
      "Epoch 124/150\n",
      "250/250 [==============================] - 0s 119us/step - loss: 0.5899 - acc: 0.7040 - val_loss: 0.6735 - val_acc: 0.6574\n",
      "Epoch 125/150\n",
      "250/250 [==============================] - 0s 150us/step - loss: 0.5896 - acc: 0.7040 - val_loss: 0.6714 - val_acc: 0.6574\n",
      "Epoch 126/150\n",
      "250/250 [==============================] - 0s 113us/step - loss: 0.5902 - acc: 0.7040 - val_loss: 0.6721 - val_acc: 0.6574\n",
      "Epoch 127/150\n",
      "250/250 [==============================] - 0s 112us/step - loss: 0.5901 - acc: 0.7040 - val_loss: 0.6729 - val_acc: 0.6574\n",
      "Epoch 128/150\n",
      "250/250 [==============================] - 0s 110us/step - loss: 0.5894 - acc: 0.7040 - val_loss: 0.6727 - val_acc: 0.6574\n",
      "Epoch 129/150\n",
      "250/250 [==============================] - 0s 109us/step - loss: 0.5897 - acc: 0.7040 - val_loss: 0.6698 - val_acc: 0.6574\n",
      "Epoch 130/150\n",
      "250/250 [==============================] - 0s 103us/step - loss: 0.5899 - acc: 0.7040 - val_loss: 0.6690 - val_acc: 0.6574\n",
      "Epoch 131/150\n",
      "250/250 [==============================] - 0s 109us/step - loss: 0.5891 - acc: 0.7040 - val_loss: 0.6723 - val_acc: 0.6574\n",
      "Epoch 132/150\n",
      "250/250 [==============================] - 0s 112us/step - loss: 0.5891 - acc: 0.7040 - val_loss: 0.6746 - val_acc: 0.6574\n",
      "Epoch 133/150\n",
      "250/250 [==============================] - 0s 103us/step - loss: 0.5890 - acc: 0.7040 - val_loss: 0.6727 - val_acc: 0.6574\n",
      "Epoch 134/150\n",
      "250/250 [==============================] - 0s 108us/step - loss: 0.5888 - acc: 0.7040 - val_loss: 0.6732 - val_acc: 0.6574\n",
      "Epoch 135/150\n",
      "250/250 [==============================] - 0s 112us/step - loss: 0.5898 - acc: 0.7040 - val_loss: 0.6704 - val_acc: 0.6574\n",
      "Epoch 136/150\n",
      "250/250 [==============================] - 0s 108us/step - loss: 0.5889 - acc: 0.7040 - val_loss: 0.6751 - val_acc: 0.6574\n",
      "Epoch 137/150\n",
      "250/250 [==============================] - 0s 113us/step - loss: 0.5889 - acc: 0.7040 - val_loss: 0.6732 - val_acc: 0.6574\n",
      "Epoch 138/150\n",
      "250/250 [==============================] - 0s 113us/step - loss: 0.5889 - acc: 0.7040 - val_loss: 0.6742 - val_acc: 0.6574\n",
      "Epoch 139/150\n",
      "250/250 [==============================] - 0s 111us/step - loss: 0.5882 - acc: 0.7040 - val_loss: 0.6731 - val_acc: 0.6574\n",
      "Epoch 140/150\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4731 - acc: 0.800 - 0s 125us/step - loss: 0.5884 - acc: 0.7040 - val_loss: 0.6750 - val_acc: 0.6574\n",
      "Epoch 141/150\n",
      "250/250 [==============================] - 0s 118us/step - loss: 0.5881 - acc: 0.7040 - val_loss: 0.6742 - val_acc: 0.6574\n",
      "Epoch 142/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.5881 - acc: 0.7120 - val_loss: 0.6736 - val_acc: 0.6574\n",
      "Epoch 143/150\n",
      "250/250 [==============================] - 0s 116us/step - loss: 0.5883 - acc: 0.7160 - val_loss: 0.6752 - val_acc: 0.6574\n",
      "Epoch 144/150\n",
      "250/250 [==============================] - 0s 124us/step - loss: 0.5884 - acc: 0.7160 - val_loss: 0.6732 - val_acc: 0.6574\n",
      "Epoch 145/150\n",
      "250/250 [==============================] - 0s 123us/step - loss: 0.5881 - acc: 0.7080 - val_loss: 0.6733 - val_acc: 0.6574\n",
      "Epoch 146/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.5878 - acc: 0.7120 - val_loss: 0.6763 - val_acc: 0.6574\n",
      "Epoch 147/150\n",
      "250/250 [==============================] - 0s 117us/step - loss: 0.5880 - acc: 0.7120 - val_loss: 0.6756 - val_acc: 0.6574\n",
      "Epoch 148/150\n",
      "250/250 [==============================] - 0s 122us/step - loss: 0.5879 - acc: 0.7160 - val_loss: 0.6757 - val_acc: 0.6574\n",
      "Epoch 149/150\n",
      "250/250 [==============================] - 0s 126us/step - loss: 0.5877 - acc: 0.7160 - val_loss: 0.6774 - val_acc: 0.6574\n",
      "Epoch 150/150\n",
      "250/250 [==============================] - 0s 120us/step - loss: 0.5882 - acc: 0.7160 - val_loss: 0.6751 - val_acc: 0.6574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2a783748>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train_1, Y_train_1, batch_size=10, epochs=150, validation_data = (X_test_1, Y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6662720485969826\n"
     ]
    }
   ],
   "source": [
    "# Here we find out the accuracy of the \n",
    "# predictions made on the binary encoded data features\n",
    "# that have been run through  a deep learnng model\n",
    "y_predict_1 = model_1.predict(X_test_1)\n",
    "y_predict_1 = np.where(y_predict_1>0.5,1,0)\n",
    "y_predict_1 = (y_predict_1)\n",
    "y_predict_1\n",
    "scores_1 = model_1.evaluate(X_test_1, Y_test_1, verbose=0)\n",
    "print(np.mean(scores_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive 37\n",
      "False Negative 20\n",
      "False Positive 17\n",
      "True Negative 34\n",
      "Accuracy of classification in deep learning: 0.6574074074074074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm1 = confusion_matrix(Y_test_1, y_predict_1) # confusion matrix on binary\n",
    "# encoded input data features\n",
    "cm1\n",
    "true_pos = cm1[0][0]\n",
    "false_neg = cm1[0][1]\n",
    "false_pos = cm1[1][0]\n",
    "true_neg = cm1[1][1]\n",
    "print(\"True Positive {}\".format(true_pos))\n",
    "print(\"False Negative {}\".format(false_neg))\n",
    "print(\"False Positive {}\".format(false_pos))\n",
    "print(\"True Negative {}\".format(true_neg))\n",
    "accuracy = (true_pos+true_neg)/(true_pos+false_neg+false_pos+true_neg)\n",
    "print (\"Accuracy of classification in deep learning: {}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = LogisticRegression()\n",
    "cl.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl1 = LogisticRegression()\n",
    "cl1.fit(X_train_1,Y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.60\n"
     ]
    }
   ],
   "source": [
    "y_pred = cl.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(cl.score(X, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.68\n"
     ]
    }
   ],
   "source": [
    "y_pred = cl1.predict(X_test_1)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(cl.score(X_1, Y_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf1 = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf1.fit(X_train_1, Y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5740740740740741"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(X_test)\n",
    "cl.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6574074074074074"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions_1 = rf.predict(X_test_1)\n",
    "cl1.score(X_test_1, Y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Game outcome</th>\n",
       "      <th>Number of top players (In Top 100)</th>\n",
       "      <th>Top scorer (weighted goals) contribution</th>\n",
       "      <th>Top player ratings (total)</th>\n",
       "      <th>Total assists (In Top 100)</th>\n",
       "      <th>Team Versatility score</th>\n",
       "      <th>FIFA 20 rating (sum)</th>\n",
       "      <th>Num top players metric</th>\n",
       "      <th>Top scorer metric</th>\n",
       "      <th>...</th>\n",
       "      <th>Total assists metric</th>\n",
       "      <th>Team Versatility metric</th>\n",
       "      <th>FIFA 20 rating metric</th>\n",
       "      <th>Ignore</th>\n",
       "      <th>Number of top players (In Top 100).1</th>\n",
       "      <th>Top scorer (weighted goals) contribution.1</th>\n",
       "      <th>Top player ratings (total).1</th>\n",
       "      <th>Total assists (In Top 100).1</th>\n",
       "      <th>Team Versatility score.1</th>\n",
       "      <th>FIFA 20 rating (sum).1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Game</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.304343</td>\n",
       "      <td>-0.896099</td>\n",
       "      <td>-0.893210</td>\n",
       "      <td>-0.902340</td>\n",
       "      <td>-0.879918</td>\n",
       "      <td>-0.230174</td>\n",
       "      <td>-0.943017</td>\n",
       "      <td>-0.552573</td>\n",
       "      <td>-0.557884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562553</td>\n",
       "      <td>-0.149510</td>\n",
       "      <td>-0.599578</td>\n",
       "      <td>-0.019214</td>\n",
       "      <td>-0.896099</td>\n",
       "      <td>-0.893210</td>\n",
       "      <td>-0.902340</td>\n",
       "      <td>-0.879918</td>\n",
       "      <td>-0.230174</td>\n",
       "      <td>-0.943017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game outcome</th>\n",
       "      <td>-0.304343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290888</td>\n",
       "      <td>0.301381</td>\n",
       "      <td>0.289678</td>\n",
       "      <td>0.317318</td>\n",
       "      <td>0.099073</td>\n",
       "      <td>0.309703</td>\n",
       "      <td>0.308207</td>\n",
       "      <td>0.284934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380179</td>\n",
       "      <td>0.117318</td>\n",
       "      <td>0.329691</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>0.290888</td>\n",
       "      <td>0.301381</td>\n",
       "      <td>0.289678</td>\n",
       "      <td>0.317318</td>\n",
       "      <td>0.099073</td>\n",
       "      <td>0.309703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of top players (In Top 100)</th>\n",
       "      <td>-0.896099</td>\n",
       "      <td>0.290888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877213</td>\n",
       "      <td>0.976607</td>\n",
       "      <td>0.828643</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.833813</td>\n",
       "      <td>0.588016</td>\n",
       "      <td>0.524762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506234</td>\n",
       "      <td>0.128078</td>\n",
       "      <td>0.524253</td>\n",
       "      <td>0.019498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877213</td>\n",
       "      <td>0.976607</td>\n",
       "      <td>0.828643</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.833813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top scorer (weighted goals) contribution</th>\n",
       "      <td>-0.893210</td>\n",
       "      <td>0.301381</td>\n",
       "      <td>0.877213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929065</td>\n",
       "      <td>0.929441</td>\n",
       "      <td>0.296652</td>\n",
       "      <td>0.907740</td>\n",
       "      <td>0.536770</td>\n",
       "      <td>0.588383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559863</td>\n",
       "      <td>0.188330</td>\n",
       "      <td>0.548973</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.877213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929065</td>\n",
       "      <td>0.929441</td>\n",
       "      <td>0.296652</td>\n",
       "      <td>0.907740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top player ratings (total)</th>\n",
       "      <td>-0.902340</td>\n",
       "      <td>0.289678</td>\n",
       "      <td>0.976607</td>\n",
       "      <td>0.929065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867816</td>\n",
       "      <td>0.219558</td>\n",
       "      <td>0.870430</td>\n",
       "      <td>0.588395</td>\n",
       "      <td>0.549689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527743</td>\n",
       "      <td>0.143037</td>\n",
       "      <td>0.541007</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.976607</td>\n",
       "      <td>0.929065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867816</td>\n",
       "      <td>0.219558</td>\n",
       "      <td>0.870430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total assists (In Top 100)</th>\n",
       "      <td>-0.879918</td>\n",
       "      <td>0.317318</td>\n",
       "      <td>0.828643</td>\n",
       "      <td>0.929441</td>\n",
       "      <td>0.867816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447078</td>\n",
       "      <td>0.841303</td>\n",
       "      <td>0.495540</td>\n",
       "      <td>0.541456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585204</td>\n",
       "      <td>0.274785</td>\n",
       "      <td>0.507470</td>\n",
       "      <td>0.043153</td>\n",
       "      <td>0.828643</td>\n",
       "      <td>0.929441</td>\n",
       "      <td>0.867816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447078</td>\n",
       "      <td>0.841303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team Versatility score</th>\n",
       "      <td>-0.230174</td>\n",
       "      <td>0.099073</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.296652</td>\n",
       "      <td>0.219558</td>\n",
       "      <td>0.447078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196893</td>\n",
       "      <td>0.116905</td>\n",
       "      <td>0.161921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244767</td>\n",
       "      <td>0.597822</td>\n",
       "      <td>0.108788</td>\n",
       "      <td>0.048513</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.296652</td>\n",
       "      <td>0.219558</td>\n",
       "      <td>0.447078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIFA 20 rating (sum)</th>\n",
       "      <td>-0.943017</td>\n",
       "      <td>0.309703</td>\n",
       "      <td>0.833813</td>\n",
       "      <td>0.907740</td>\n",
       "      <td>0.870430</td>\n",
       "      <td>0.841303</td>\n",
       "      <td>0.196893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517676</td>\n",
       "      <td>0.546312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529031</td>\n",
       "      <td>0.127554</td>\n",
       "      <td>0.594815</td>\n",
       "      <td>0.038410</td>\n",
       "      <td>0.833813</td>\n",
       "      <td>0.907740</td>\n",
       "      <td>0.870430</td>\n",
       "      <td>0.841303</td>\n",
       "      <td>0.196893</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num top players metric</th>\n",
       "      <td>-0.552573</td>\n",
       "      <td>0.308207</td>\n",
       "      <td>0.588016</td>\n",
       "      <td>0.536770</td>\n",
       "      <td>0.588395</td>\n",
       "      <td>0.495540</td>\n",
       "      <td>0.116905</td>\n",
       "      <td>0.517676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.710845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681112</td>\n",
       "      <td>0.106471</td>\n",
       "      <td>0.710101</td>\n",
       "      <td>0.018691</td>\n",
       "      <td>0.588016</td>\n",
       "      <td>0.536770</td>\n",
       "      <td>0.588395</td>\n",
       "      <td>0.495540</td>\n",
       "      <td>0.116905</td>\n",
       "      <td>0.517676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top scorer metric</th>\n",
       "      <td>-0.557884</td>\n",
       "      <td>0.284934</td>\n",
       "      <td>0.524762</td>\n",
       "      <td>0.588383</td>\n",
       "      <td>0.549689</td>\n",
       "      <td>0.541456</td>\n",
       "      <td>0.161921</td>\n",
       "      <td>0.546312</td>\n",
       "      <td>0.710845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771151</td>\n",
       "      <td>0.195543</td>\n",
       "      <td>0.731822</td>\n",
       "      <td>0.027637</td>\n",
       "      <td>0.524762</td>\n",
       "      <td>0.588383</td>\n",
       "      <td>0.549689</td>\n",
       "      <td>0.541456</td>\n",
       "      <td>0.161921</td>\n",
       "      <td>0.546312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top player ratings metric</th>\n",
       "      <td>-0.555946</td>\n",
       "      <td>0.307263</td>\n",
       "      <td>0.573093</td>\n",
       "      <td>0.526427</td>\n",
       "      <td>0.578383</td>\n",
       "      <td>0.489689</td>\n",
       "      <td>0.111639</td>\n",
       "      <td>0.518016</td>\n",
       "      <td>0.890998</td>\n",
       "      <td>0.743063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704449</td>\n",
       "      <td>0.139665</td>\n",
       "      <td>0.743202</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>0.573093</td>\n",
       "      <td>0.526427</td>\n",
       "      <td>0.578383</td>\n",
       "      <td>0.489689</td>\n",
       "      <td>0.111639</td>\n",
       "      <td>0.518016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total assists metric</th>\n",
       "      <td>-0.562553</td>\n",
       "      <td>0.380179</td>\n",
       "      <td>0.506234</td>\n",
       "      <td>0.559863</td>\n",
       "      <td>0.527743</td>\n",
       "      <td>0.585204</td>\n",
       "      <td>0.244767</td>\n",
       "      <td>0.529031</td>\n",
       "      <td>0.681112</td>\n",
       "      <td>0.771151</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.257180</td>\n",
       "      <td>0.670197</td>\n",
       "      <td>0.025677</td>\n",
       "      <td>0.506234</td>\n",
       "      <td>0.559863</td>\n",
       "      <td>0.527743</td>\n",
       "      <td>0.585204</td>\n",
       "      <td>0.244767</td>\n",
       "      <td>0.529031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team Versatility metric</th>\n",
       "      <td>-0.149510</td>\n",
       "      <td>0.117318</td>\n",
       "      <td>0.128078</td>\n",
       "      <td>0.188330</td>\n",
       "      <td>0.143037</td>\n",
       "      <td>0.274785</td>\n",
       "      <td>0.597822</td>\n",
       "      <td>0.127554</td>\n",
       "      <td>0.106471</td>\n",
       "      <td>0.195543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117348</td>\n",
       "      <td>-0.012141</td>\n",
       "      <td>0.128078</td>\n",
       "      <td>0.188330</td>\n",
       "      <td>0.143037</td>\n",
       "      <td>0.274785</td>\n",
       "      <td>0.597822</td>\n",
       "      <td>0.127554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIFA 20 rating metric</th>\n",
       "      <td>-0.599578</td>\n",
       "      <td>0.329691</td>\n",
       "      <td>0.524253</td>\n",
       "      <td>0.548973</td>\n",
       "      <td>0.541007</td>\n",
       "      <td>0.507470</td>\n",
       "      <td>0.108788</td>\n",
       "      <td>0.594815</td>\n",
       "      <td>0.710101</td>\n",
       "      <td>0.731822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670197</td>\n",
       "      <td>0.117348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009387</td>\n",
       "      <td>0.524253</td>\n",
       "      <td>0.548973</td>\n",
       "      <td>0.541007</td>\n",
       "      <td>0.507470</td>\n",
       "      <td>0.108788</td>\n",
       "      <td>0.594815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ignore</th>\n",
       "      <td>-0.019214</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>0.019498</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.043153</td>\n",
       "      <td>0.048513</td>\n",
       "      <td>0.038410</td>\n",
       "      <td>0.018691</td>\n",
       "      <td>0.027637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025677</td>\n",
       "      <td>-0.012141</td>\n",
       "      <td>0.009387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019498</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.043153</td>\n",
       "      <td>0.048513</td>\n",
       "      <td>0.038410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of top players (In Top 100).1</th>\n",
       "      <td>-0.896099</td>\n",
       "      <td>0.290888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877213</td>\n",
       "      <td>0.976607</td>\n",
       "      <td>0.828643</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.833813</td>\n",
       "      <td>0.588016</td>\n",
       "      <td>0.524762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506234</td>\n",
       "      <td>0.128078</td>\n",
       "      <td>0.524253</td>\n",
       "      <td>0.019498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877213</td>\n",
       "      <td>0.976607</td>\n",
       "      <td>0.828643</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.833813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top scorer (weighted goals) contribution.1</th>\n",
       "      <td>-0.893210</td>\n",
       "      <td>0.301381</td>\n",
       "      <td>0.877213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929065</td>\n",
       "      <td>0.929441</td>\n",
       "      <td>0.296652</td>\n",
       "      <td>0.907740</td>\n",
       "      <td>0.536770</td>\n",
       "      <td>0.588383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559863</td>\n",
       "      <td>0.188330</td>\n",
       "      <td>0.548973</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.877213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929065</td>\n",
       "      <td>0.929441</td>\n",
       "      <td>0.296652</td>\n",
       "      <td>0.907740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top player ratings (total).1</th>\n",
       "      <td>-0.902340</td>\n",
       "      <td>0.289678</td>\n",
       "      <td>0.976607</td>\n",
       "      <td>0.929065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867816</td>\n",
       "      <td>0.219558</td>\n",
       "      <td>0.870430</td>\n",
       "      <td>0.588395</td>\n",
       "      <td>0.549689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527743</td>\n",
       "      <td>0.143037</td>\n",
       "      <td>0.541007</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.976607</td>\n",
       "      <td>0.929065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867816</td>\n",
       "      <td>0.219558</td>\n",
       "      <td>0.870430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total assists (In Top 100).1</th>\n",
       "      <td>-0.879918</td>\n",
       "      <td>0.317318</td>\n",
       "      <td>0.828643</td>\n",
       "      <td>0.929441</td>\n",
       "      <td>0.867816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447078</td>\n",
       "      <td>0.841303</td>\n",
       "      <td>0.495540</td>\n",
       "      <td>0.541456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585204</td>\n",
       "      <td>0.274785</td>\n",
       "      <td>0.507470</td>\n",
       "      <td>0.043153</td>\n",
       "      <td>0.828643</td>\n",
       "      <td>0.929441</td>\n",
       "      <td>0.867816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447078</td>\n",
       "      <td>0.841303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team Versatility score.1</th>\n",
       "      <td>-0.230174</td>\n",
       "      <td>0.099073</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.296652</td>\n",
       "      <td>0.219558</td>\n",
       "      <td>0.447078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196893</td>\n",
       "      <td>0.116905</td>\n",
       "      <td>0.161921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244767</td>\n",
       "      <td>0.597822</td>\n",
       "      <td>0.108788</td>\n",
       "      <td>0.048513</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.296652</td>\n",
       "      <td>0.219558</td>\n",
       "      <td>0.447078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIFA 20 rating (sum).1</th>\n",
       "      <td>-0.943017</td>\n",
       "      <td>0.309703</td>\n",
       "      <td>0.833813</td>\n",
       "      <td>0.907740</td>\n",
       "      <td>0.870430</td>\n",
       "      <td>0.841303</td>\n",
       "      <td>0.196893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517676</td>\n",
       "      <td>0.546312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529031</td>\n",
       "      <td>0.127554</td>\n",
       "      <td>0.594815</td>\n",
       "      <td>0.038410</td>\n",
       "      <td>0.833813</td>\n",
       "      <td>0.907740</td>\n",
       "      <td>0.870430</td>\n",
       "      <td>0.841303</td>\n",
       "      <td>0.196893</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Game  Game outcome  \\\n",
       "Game                                        1.000000     -0.304343   \n",
       "Game outcome                               -0.304343      1.000000   \n",
       "Number of top players (In Top 100)         -0.896099      0.290888   \n",
       "Top scorer (weighted goals) contribution   -0.893210      0.301381   \n",
       "Top player ratings (total)                 -0.902340      0.289678   \n",
       "Total assists (In Top 100)                 -0.879918      0.317318   \n",
       "Team Versatility score                     -0.230174      0.099073   \n",
       "FIFA 20 rating (sum)                       -0.943017      0.309703   \n",
       "Num top players metric                     -0.552573      0.308207   \n",
       "Top scorer metric                          -0.557884      0.284934   \n",
       "Top player ratings metric                  -0.555946      0.307263   \n",
       "Total assists metric                       -0.562553      0.380179   \n",
       "Team Versatility metric                    -0.149510      0.117318   \n",
       "FIFA 20 rating metric                      -0.599578      0.329691   \n",
       "Ignore                                     -0.019214      0.029013   \n",
       "Number of top players (In Top 100).1       -0.896099      0.290888   \n",
       "Top scorer (weighted goals) contribution.1 -0.893210      0.301381   \n",
       "Top player ratings (total).1               -0.902340      0.289678   \n",
       "Total assists (In Top 100).1               -0.879918      0.317318   \n",
       "Team Versatility score.1                   -0.230174      0.099073   \n",
       "FIFA 20 rating (sum).1                     -0.943017      0.309703   \n",
       "\n",
       "                                            Number of top players (In Top 100)  \\\n",
       "Game                                                                 -0.896099   \n",
       "Game outcome                                                          0.290888   \n",
       "Number of top players (In Top 100)                                    1.000000   \n",
       "Top scorer (weighted goals) contribution                              0.877213   \n",
       "Top player ratings (total)                                            0.976607   \n",
       "Total assists (In Top 100)                                            0.828643   \n",
       "Team Versatility score                                                0.183901   \n",
       "FIFA 20 rating (sum)                                                  0.833813   \n",
       "Num top players metric                                                0.588016   \n",
       "Top scorer metric                                                     0.524762   \n",
       "Top player ratings metric                                             0.573093   \n",
       "Total assists metric                                                  0.506234   \n",
       "Team Versatility metric                                               0.128078   \n",
       "FIFA 20 rating metric                                                 0.524253   \n",
       "Ignore                                                                0.019498   \n",
       "Number of top players (In Top 100).1                                  1.000000   \n",
       "Top scorer (weighted goals) contribution.1                            0.877213   \n",
       "Top player ratings (total).1                                          0.976607   \n",
       "Total assists (In Top 100).1                                          0.828643   \n",
       "Team Versatility score.1                                              0.183901   \n",
       "FIFA 20 rating (sum).1                                                0.833813   \n",
       "\n",
       "                                            Top scorer (weighted goals) contribution  \\\n",
       "Game                                                                       -0.893210   \n",
       "Game outcome                                                                0.301381   \n",
       "Number of top players (In Top 100)                                          0.877213   \n",
       "Top scorer (weighted goals) contribution                                    1.000000   \n",
       "Top player ratings (total)                                                  0.929065   \n",
       "Total assists (In Top 100)                                                  0.929441   \n",
       "Team Versatility score                                                      0.296652   \n",
       "FIFA 20 rating (sum)                                                        0.907740   \n",
       "Num top players metric                                                      0.536770   \n",
       "Top scorer metric                                                           0.588383   \n",
       "Top player ratings metric                                                   0.526427   \n",
       "Total assists metric                                                        0.559863   \n",
       "Team Versatility metric                                                     0.188330   \n",
       "FIFA 20 rating metric                                                       0.548973   \n",
       "Ignore                                                                      0.015621   \n",
       "Number of top players (In Top 100).1                                        0.877213   \n",
       "Top scorer (weighted goals) contribution.1                                  1.000000   \n",
       "Top player ratings (total).1                                                0.929065   \n",
       "Total assists (In Top 100).1                                                0.929441   \n",
       "Team Versatility score.1                                                    0.296652   \n",
       "FIFA 20 rating (sum).1                                                      0.907740   \n",
       "\n",
       "                                            Top player ratings (total)  \\\n",
       "Game                                                         -0.902340   \n",
       "Game outcome                                                  0.289678   \n",
       "Number of top players (In Top 100)                            0.976607   \n",
       "Top scorer (weighted goals) contribution                      0.929065   \n",
       "Top player ratings (total)                                    1.000000   \n",
       "Total assists (In Top 100)                                    0.867816   \n",
       "Team Versatility score                                        0.219558   \n",
       "FIFA 20 rating (sum)                                          0.870430   \n",
       "Num top players metric                                        0.588395   \n",
       "Top scorer metric                                             0.549689   \n",
       "Top player ratings metric                                     0.578383   \n",
       "Total assists metric                                          0.527743   \n",
       "Team Versatility metric                                       0.143037   \n",
       "FIFA 20 rating metric                                         0.541007   \n",
       "Ignore                                                        0.024858   \n",
       "Number of top players (In Top 100).1                          0.976607   \n",
       "Top scorer (weighted goals) contribution.1                    0.929065   \n",
       "Top player ratings (total).1                                  1.000000   \n",
       "Total assists (In Top 100).1                                  0.867816   \n",
       "Team Versatility score.1                                      0.219558   \n",
       "FIFA 20 rating (sum).1                                        0.870430   \n",
       "\n",
       "                                            Total assists (In Top 100)  \\\n",
       "Game                                                         -0.879918   \n",
       "Game outcome                                                  0.317318   \n",
       "Number of top players (In Top 100)                            0.828643   \n",
       "Top scorer (weighted goals) contribution                      0.929441   \n",
       "Top player ratings (total)                                    0.867816   \n",
       "Total assists (In Top 100)                                    1.000000   \n",
       "Team Versatility score                                        0.447078   \n",
       "FIFA 20 rating (sum)                                          0.841303   \n",
       "Num top players metric                                        0.495540   \n",
       "Top scorer metric                                             0.541456   \n",
       "Top player ratings metric                                     0.489689   \n",
       "Total assists metric                                          0.585204   \n",
       "Team Versatility metric                                       0.274785   \n",
       "FIFA 20 rating metric                                         0.507470   \n",
       "Ignore                                                        0.043153   \n",
       "Number of top players (In Top 100).1                          0.828643   \n",
       "Top scorer (weighted goals) contribution.1                    0.929441   \n",
       "Top player ratings (total).1                                  0.867816   \n",
       "Total assists (In Top 100).1                                  1.000000   \n",
       "Team Versatility score.1                                      0.447078   \n",
       "FIFA 20 rating (sum).1                                        0.841303   \n",
       "\n",
       "                                            Team Versatility score  \\\n",
       "Game                                                     -0.230174   \n",
       "Game outcome                                              0.099073   \n",
       "Number of top players (In Top 100)                        0.183901   \n",
       "Top scorer (weighted goals) contribution                  0.296652   \n",
       "Top player ratings (total)                                0.219558   \n",
       "Total assists (In Top 100)                                0.447078   \n",
       "Team Versatility score                                    1.000000   \n",
       "FIFA 20 rating (sum)                                      0.196893   \n",
       "Num top players metric                                    0.116905   \n",
       "Top scorer metric                                         0.161921   \n",
       "Top player ratings metric                                 0.111639   \n",
       "Total assists metric                                      0.244767   \n",
       "Team Versatility metric                                   0.597822   \n",
       "FIFA 20 rating metric                                     0.108788   \n",
       "Ignore                                                    0.048513   \n",
       "Number of top players (In Top 100).1                      0.183901   \n",
       "Top scorer (weighted goals) contribution.1                0.296652   \n",
       "Top player ratings (total).1                              0.219558   \n",
       "Total assists (In Top 100).1                              0.447078   \n",
       "Team Versatility score.1                                  1.000000   \n",
       "FIFA 20 rating (sum).1                                    0.196893   \n",
       "\n",
       "                                            FIFA 20 rating (sum)  \\\n",
       "Game                                                   -0.943017   \n",
       "Game outcome                                            0.309703   \n",
       "Number of top players (In Top 100)                      0.833813   \n",
       "Top scorer (weighted goals) contribution                0.907740   \n",
       "Top player ratings (total)                              0.870430   \n",
       "Total assists (In Top 100)                              0.841303   \n",
       "Team Versatility score                                  0.196893   \n",
       "FIFA 20 rating (sum)                                    1.000000   \n",
       "Num top players metric                                  0.517676   \n",
       "Top scorer metric                                       0.546312   \n",
       "Top player ratings metric                               0.518016   \n",
       "Total assists metric                                    0.529031   \n",
       "Team Versatility metric                                 0.127554   \n",
       "FIFA 20 rating metric                                   0.594815   \n",
       "Ignore                                                  0.038410   \n",
       "Number of top players (In Top 100).1                    0.833813   \n",
       "Top scorer (weighted goals) contribution.1              0.907740   \n",
       "Top player ratings (total).1                            0.870430   \n",
       "Total assists (In Top 100).1                            0.841303   \n",
       "Team Versatility score.1                                0.196893   \n",
       "FIFA 20 rating (sum).1                                  1.000000   \n",
       "\n",
       "                                            Num top players metric  \\\n",
       "Game                                                     -0.552573   \n",
       "Game outcome                                              0.308207   \n",
       "Number of top players (In Top 100)                        0.588016   \n",
       "Top scorer (weighted goals) contribution                  0.536770   \n",
       "Top player ratings (total)                                0.588395   \n",
       "Total assists (In Top 100)                                0.495540   \n",
       "Team Versatility score                                    0.116905   \n",
       "FIFA 20 rating (sum)                                      0.517676   \n",
       "Num top players metric                                    1.000000   \n",
       "Top scorer metric                                         0.710845   \n",
       "Top player ratings metric                                 0.890998   \n",
       "Total assists metric                                      0.681112   \n",
       "Team Versatility metric                                   0.106471   \n",
       "FIFA 20 rating metric                                     0.710101   \n",
       "Ignore                                                    0.018691   \n",
       "Number of top players (In Top 100).1                      0.588016   \n",
       "Top scorer (weighted goals) contribution.1                0.536770   \n",
       "Top player ratings (total).1                              0.588395   \n",
       "Total assists (In Top 100).1                              0.495540   \n",
       "Team Versatility score.1                                  0.116905   \n",
       "FIFA 20 rating (sum).1                                    0.517676   \n",
       "\n",
       "                                            Top scorer metric  ...  \\\n",
       "Game                                                -0.557884  ...   \n",
       "Game outcome                                         0.284934  ...   \n",
       "Number of top players (In Top 100)                   0.524762  ...   \n",
       "Top scorer (weighted goals) contribution             0.588383  ...   \n",
       "Top player ratings (total)                           0.549689  ...   \n",
       "Total assists (In Top 100)                           0.541456  ...   \n",
       "Team Versatility score                               0.161921  ...   \n",
       "FIFA 20 rating (sum)                                 0.546312  ...   \n",
       "Num top players metric                               0.710845  ...   \n",
       "Top scorer metric                                    1.000000  ...   \n",
       "Top player ratings metric                            0.743063  ...   \n",
       "Total assists metric                                 0.771151  ...   \n",
       "Team Versatility metric                              0.195543  ...   \n",
       "FIFA 20 rating metric                                0.731822  ...   \n",
       "Ignore                                               0.027637  ...   \n",
       "Number of top players (In Top 100).1                 0.524762  ...   \n",
       "Top scorer (weighted goals) contribution.1           0.588383  ...   \n",
       "Top player ratings (total).1                         0.549689  ...   \n",
       "Total assists (In Top 100).1                         0.541456  ...   \n",
       "Team Versatility score.1                             0.161921  ...   \n",
       "FIFA 20 rating (sum).1                               0.546312  ...   \n",
       "\n",
       "                                            Total assists metric  \\\n",
       "Game                                                   -0.562553   \n",
       "Game outcome                                            0.380179   \n",
       "Number of top players (In Top 100)                      0.506234   \n",
       "Top scorer (weighted goals) contribution                0.559863   \n",
       "Top player ratings (total)                              0.527743   \n",
       "Total assists (In Top 100)                              0.585204   \n",
       "Team Versatility score                                  0.244767   \n",
       "FIFA 20 rating (sum)                                    0.529031   \n",
       "Num top players metric                                  0.681112   \n",
       "Top scorer metric                                       0.771151   \n",
       "Top player ratings metric                               0.704449   \n",
       "Total assists metric                                    1.000000   \n",
       "Team Versatility metric                                 0.257180   \n",
       "FIFA 20 rating metric                                   0.670197   \n",
       "Ignore                                                  0.025677   \n",
       "Number of top players (In Top 100).1                    0.506234   \n",
       "Top scorer (weighted goals) contribution.1              0.559863   \n",
       "Top player ratings (total).1                            0.527743   \n",
       "Total assists (In Top 100).1                            0.585204   \n",
       "Team Versatility score.1                                0.244767   \n",
       "FIFA 20 rating (sum).1                                  0.529031   \n",
       "\n",
       "                                            Team Versatility metric  \\\n",
       "Game                                                      -0.149510   \n",
       "Game outcome                                               0.117318   \n",
       "Number of top players (In Top 100)                         0.128078   \n",
       "Top scorer (weighted goals) contribution                   0.188330   \n",
       "Top player ratings (total)                                 0.143037   \n",
       "Total assists (In Top 100)                                 0.274785   \n",
       "Team Versatility score                                     0.597822   \n",
       "FIFA 20 rating (sum)                                       0.127554   \n",
       "Num top players metric                                     0.106471   \n",
       "Top scorer metric                                          0.195543   \n",
       "Top player ratings metric                                  0.139665   \n",
       "Total assists metric                                       0.257180   \n",
       "Team Versatility metric                                    1.000000   \n",
       "FIFA 20 rating metric                                      0.117348   \n",
       "Ignore                                                    -0.012141   \n",
       "Number of top players (In Top 100).1                       0.128078   \n",
       "Top scorer (weighted goals) contribution.1                 0.188330   \n",
       "Top player ratings (total).1                               0.143037   \n",
       "Total assists (In Top 100).1                               0.274785   \n",
       "Team Versatility score.1                                   0.597822   \n",
       "FIFA 20 rating (sum).1                                     0.127554   \n",
       "\n",
       "                                            FIFA 20 rating metric    Ignore  \\\n",
       "Game                                                    -0.599578 -0.019214   \n",
       "Game outcome                                             0.329691  0.029013   \n",
       "Number of top players (In Top 100)                       0.524253  0.019498   \n",
       "Top scorer (weighted goals) contribution                 0.548973  0.015621   \n",
       "Top player ratings (total)                               0.541007  0.024858   \n",
       "Total assists (In Top 100)                               0.507470  0.043153   \n",
       "Team Versatility score                                   0.108788  0.048513   \n",
       "FIFA 20 rating (sum)                                     0.594815  0.038410   \n",
       "Num top players metric                                   0.710101  0.018691   \n",
       "Top scorer metric                                        0.731822  0.027637   \n",
       "Top player ratings metric                                0.743202  0.029013   \n",
       "Total assists metric                                     0.670197  0.025677   \n",
       "Team Versatility metric                                  0.117348 -0.012141   \n",
       "FIFA 20 rating metric                                    1.000000  0.009387   \n",
       "Ignore                                                   0.009387  1.000000   \n",
       "Number of top players (In Top 100).1                     0.524253  0.019498   \n",
       "Top scorer (weighted goals) contribution.1               0.548973  0.015621   \n",
       "Top player ratings (total).1                             0.541007  0.024858   \n",
       "Total assists (In Top 100).1                             0.507470  0.043153   \n",
       "Team Versatility score.1                                 0.108788  0.048513   \n",
       "FIFA 20 rating (sum).1                                   0.594815  0.038410   \n",
       "\n",
       "                                            Number of top players (In Top 100).1  \\\n",
       "Game                                                                   -0.896099   \n",
       "Game outcome                                                            0.290888   \n",
       "Number of top players (In Top 100)                                      1.000000   \n",
       "Top scorer (weighted goals) contribution                                0.877213   \n",
       "Top player ratings (total)                                              0.976607   \n",
       "Total assists (In Top 100)                                              0.828643   \n",
       "Team Versatility score                                                  0.183901   \n",
       "FIFA 20 rating (sum)                                                    0.833813   \n",
       "Num top players metric                                                  0.588016   \n",
       "Top scorer metric                                                       0.524762   \n",
       "Top player ratings metric                                               0.573093   \n",
       "Total assists metric                                                    0.506234   \n",
       "Team Versatility metric                                                 0.128078   \n",
       "FIFA 20 rating metric                                                   0.524253   \n",
       "Ignore                                                                  0.019498   \n",
       "Number of top players (In Top 100).1                                    1.000000   \n",
       "Top scorer (weighted goals) contribution.1                              0.877213   \n",
       "Top player ratings (total).1                                            0.976607   \n",
       "Total assists (In Top 100).1                                            0.828643   \n",
       "Team Versatility score.1                                                0.183901   \n",
       "FIFA 20 rating (sum).1                                                  0.833813   \n",
       "\n",
       "                                            Top scorer (weighted goals) contribution.1  \\\n",
       "Game                                                                         -0.893210   \n",
       "Game outcome                                                                  0.301381   \n",
       "Number of top players (In Top 100)                                            0.877213   \n",
       "Top scorer (weighted goals) contribution                                      1.000000   \n",
       "Top player ratings (total)                                                    0.929065   \n",
       "Total assists (In Top 100)                                                    0.929441   \n",
       "Team Versatility score                                                        0.296652   \n",
       "FIFA 20 rating (sum)                                                          0.907740   \n",
       "Num top players metric                                                        0.536770   \n",
       "Top scorer metric                                                             0.588383   \n",
       "Top player ratings metric                                                     0.526427   \n",
       "Total assists metric                                                          0.559863   \n",
       "Team Versatility metric                                                       0.188330   \n",
       "FIFA 20 rating metric                                                         0.548973   \n",
       "Ignore                                                                        0.015621   \n",
       "Number of top players (In Top 100).1                                          0.877213   \n",
       "Top scorer (weighted goals) contribution.1                                    1.000000   \n",
       "Top player ratings (total).1                                                  0.929065   \n",
       "Total assists (In Top 100).1                                                  0.929441   \n",
       "Team Versatility score.1                                                      0.296652   \n",
       "FIFA 20 rating (sum).1                                                        0.907740   \n",
       "\n",
       "                                            Top player ratings (total).1  \\\n",
       "Game                                                           -0.902340   \n",
       "Game outcome                                                    0.289678   \n",
       "Number of top players (In Top 100)                              0.976607   \n",
       "Top scorer (weighted goals) contribution                        0.929065   \n",
       "Top player ratings (total)                                      1.000000   \n",
       "Total assists (In Top 100)                                      0.867816   \n",
       "Team Versatility score                                          0.219558   \n",
       "FIFA 20 rating (sum)                                            0.870430   \n",
       "Num top players metric                                          0.588395   \n",
       "Top scorer metric                                               0.549689   \n",
       "Top player ratings metric                                       0.578383   \n",
       "Total assists metric                                            0.527743   \n",
       "Team Versatility metric                                         0.143037   \n",
       "FIFA 20 rating metric                                           0.541007   \n",
       "Ignore                                                          0.024858   \n",
       "Number of top players (In Top 100).1                            0.976607   \n",
       "Top scorer (weighted goals) contribution.1                      0.929065   \n",
       "Top player ratings (total).1                                    1.000000   \n",
       "Total assists (In Top 100).1                                    0.867816   \n",
       "Team Versatility score.1                                        0.219558   \n",
       "FIFA 20 rating (sum).1                                          0.870430   \n",
       "\n",
       "                                            Total assists (In Top 100).1  \\\n",
       "Game                                                           -0.879918   \n",
       "Game outcome                                                    0.317318   \n",
       "Number of top players (In Top 100)                              0.828643   \n",
       "Top scorer (weighted goals) contribution                        0.929441   \n",
       "Top player ratings (total)                                      0.867816   \n",
       "Total assists (In Top 100)                                      1.000000   \n",
       "Team Versatility score                                          0.447078   \n",
       "FIFA 20 rating (sum)                                            0.841303   \n",
       "Num top players metric                                          0.495540   \n",
       "Top scorer metric                                               0.541456   \n",
       "Top player ratings metric                                       0.489689   \n",
       "Total assists metric                                            0.585204   \n",
       "Team Versatility metric                                         0.274785   \n",
       "FIFA 20 rating metric                                           0.507470   \n",
       "Ignore                                                          0.043153   \n",
       "Number of top players (In Top 100).1                            0.828643   \n",
       "Top scorer (weighted goals) contribution.1                      0.929441   \n",
       "Top player ratings (total).1                                    0.867816   \n",
       "Total assists (In Top 100).1                                    1.000000   \n",
       "Team Versatility score.1                                        0.447078   \n",
       "FIFA 20 rating (sum).1                                          0.841303   \n",
       "\n",
       "                                            Team Versatility score.1  \\\n",
       "Game                                                       -0.230174   \n",
       "Game outcome                                                0.099073   \n",
       "Number of top players (In Top 100)                          0.183901   \n",
       "Top scorer (weighted goals) contribution                    0.296652   \n",
       "Top player ratings (total)                                  0.219558   \n",
       "Total assists (In Top 100)                                  0.447078   \n",
       "Team Versatility score                                      1.000000   \n",
       "FIFA 20 rating (sum)                                        0.196893   \n",
       "Num top players metric                                      0.116905   \n",
       "Top scorer metric                                           0.161921   \n",
       "Top player ratings metric                                   0.111639   \n",
       "Total assists metric                                        0.244767   \n",
       "Team Versatility metric                                     0.597822   \n",
       "FIFA 20 rating metric                                       0.108788   \n",
       "Ignore                                                      0.048513   \n",
       "Number of top players (In Top 100).1                        0.183901   \n",
       "Top scorer (weighted goals) contribution.1                  0.296652   \n",
       "Top player ratings (total).1                                0.219558   \n",
       "Total assists (In Top 100).1                                0.447078   \n",
       "Team Versatility score.1                                    1.000000   \n",
       "FIFA 20 rating (sum).1                                      0.196893   \n",
       "\n",
       "                                            FIFA 20 rating (sum).1  \n",
       "Game                                                     -0.943017  \n",
       "Game outcome                                              0.309703  \n",
       "Number of top players (In Top 100)                        0.833813  \n",
       "Top scorer (weighted goals) contribution                  0.907740  \n",
       "Top player ratings (total)                                0.870430  \n",
       "Total assists (In Top 100)                                0.841303  \n",
       "Team Versatility score                                    0.196893  \n",
       "FIFA 20 rating (sum)                                      1.000000  \n",
       "Num top players metric                                    0.517676  \n",
       "Top scorer metric                                         0.546312  \n",
       "Top player ratings metric                                 0.518016  \n",
       "Total assists metric                                      0.529031  \n",
       "Team Versatility metric                                   0.127554  \n",
       "FIFA 20 rating metric                                     0.594815  \n",
       "Ignore                                                    0.038410  \n",
       "Number of top players (In Top 100).1                      0.833813  \n",
       "Top scorer (weighted goals) contribution.1                0.907740  \n",
       "Top player ratings (total).1                              0.870430  \n",
       "Total assists (In Top 100).1                              0.841303  \n",
       "Team Versatility score.1                                  0.196893  \n",
       "FIFA 20 rating (sum).1                                    1.000000  \n",
       "\n",
       "[21 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr() # find correlation of each input features to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84981767, 0.09967697])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform Principal Component Analysis on the data.\n",
    "# reduce dimensions to 2 principal components (2D)\n",
    "# on the data features that are not binary-encoded\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "pca = PCA(n_components=2)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65927612, 0.16237311])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same as above to the binary encoded input features\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "pca1 = PCA(n_components=2)\n",
    "X_train_1 = pca.fit_transform(X_train_1)\n",
    "X_test_1 = pca.transform(X_test_1)\n",
    "explained_variance_1 = pca.explained_variance_ratio_\n",
    "explained_variance_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set (i.e. the set without binary encoded inputs)\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set (i.e the binary-encoded inputs)\n",
    "classifier1 = LogisticRegression(random_state=0)\n",
    "classifier1.fit(X_train_1,Y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results after performing binary encoding on the data set input features\n",
    "y_pred1 = classifier.predict(X_test_1)\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive 37\n",
      "False Negative 20\n",
      "False Positive 31\n",
      "True Negative 20\n",
      "Accuracy of classification in logistic regression: 0.5277777777777778\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_log_reg = confusion_matrix(Y_test,y_pred)\n",
    "cm_log_reg\n",
    "\n",
    "true_pos = cm_log_reg[0][0]\n",
    "false_neg = cm_log_reg[0][1]\n",
    "false_pos = cm_log_reg[1][0]\n",
    "true_neg = cm_log_reg[1][1]\n",
    "print(\"True Positive {}\".format(true_pos))\n",
    "print(\"False Negative {}\".format(false_neg))\n",
    "print(\"False Positive {}\".format(false_pos))\n",
    "print(\"True Negative {}\".format(true_neg))\n",
    "accuracy = (true_pos+true_neg)/(true_pos+false_neg+false_pos+true_neg)\n",
    "print (\"Accuracy of classification in logistic regression: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive 36\n",
      "False Negative 21\n",
      "False Positive 17\n",
      "True Negative 34\n",
      "Accuracy of classification in log_reg_1: 0.6481481481481481\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix for logistic regression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_log_reg_1 = confusion_matrix(Y_test_1,y_pred1)\n",
    "cm_log_reg_1\n",
    "\n",
    "true_pos = cm_log_reg_1[0][0]\n",
    "false_neg = cm_log_reg_1[0][1]\n",
    "false_pos = cm_log_reg_1[1][0]\n",
    "true_neg = cm_log_reg_1[1][1]\n",
    "print(\"True Positive {}\".format(true_pos))\n",
    "print(\"False Negative {}\".format(false_neg))\n",
    "print(\"False Positive {}\".format(false_pos))\n",
    "print(\"True Negative {}\".format(true_neg))\n",
    "accuracy = (true_pos+true_neg)/(true_pos+false_neg+false_pos+true_neg)\n",
    "print (\"Accuracy of classification in log_reg_1: {}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, Y_set = X_train, Y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:,0].min() - 1,\n",
    "                               stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                    np.arange(start = X_set[:, 1].min() - 1,\n",
    "                              stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(),\n",
    "                                                     X2.ravel()]).T).reshape(X1.shape),\n",
    "            alpha = 0.75, cmap = ListedColormap(('red','green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(Y_set)):\n",
    "    plt.scatter(X_set[Y_set == j, 0], X_set[Y_set == j, 1],\n",
    "               c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Logistic Regression (Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the Training set results of binary encoded inputs\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set_1, Y_set_1 = X_train_1, Y_train_1\n",
    "X1_1, X2_1 = np.meshgrid(np.arange(start = X_set_1[:,0].min() - 1,\n",
    "                               stop = X_set_1[:, 0].max() + 1, step = 0.01),\n",
    "                    np.arange(start = X_set_1[:, 1].min() - 1,\n",
    "                              stop = X_set_1[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1_1, X2_1, classifier.predict(np.array([X1_1.ravel(),\n",
    "                                                     X2_1.ravel()]).T).reshape(X1_1.shape),\n",
    "            alpha = 0.75, cmap = ListedColormap(('red','green')))\n",
    "plt.xlim(X1_1.min(), X1_1.max())\n",
    "plt.ylim(X2_1.min(), X2_1.max())\n",
    "for i, j in enumerate(np.unique(Y_set_1)):\n",
    "    plt.scatter(X_set_1[Y_set_1 == j, 0], X_set_1[Y_set_1 == j, 1],\n",
    "               c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Logistic Regression (Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='poly', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a support vector cclassifier to the training set\n",
    "from sklearn.svm import SVC\n",
    "cf = SVC(kernel='poly', random_state=0)\n",
    "cf.fit(X_set, Y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='poly', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a support vector cclassifier to the training set\n",
    "from sklearn.svm import SVC\n",
    "cf1 = SVC(kernel='poly', random_state=0)\n",
    "cf1.fit(X_set_1, Y_set_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_set1, Y_set1 = X_set, Y_set\n",
    "X1a, X2a = np.meshgrid(np.arange(start = X_set1[:,0].min() - 1,\n",
    "                               stop = X_set1[:, 0].max() + 1, step = 0.01),\n",
    "                    np.arange(start = X_set1[:, 1].min() - 1,\n",
    "                              stop = X_set1[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1a, X2a, cf.predict(np.array([X1.ravel(),\n",
    "                                                     X2a.ravel()]).T).reshape(X1a.shape),\n",
    "            alpha = 0.75, cmap = ListedColormap(('red','green')))\n",
    "plt.xlim(X1a.min(), X1a.max())\n",
    "plt.ylim(X2a.min(), X2a.max())\n",
    "for i, j in enumerate(np.unique(Y_set1)):\n",
    "    plt.scatter(X_set1[Y_set1 == j, 0], X_set1[Y_set1 == j, 1],\n",
    "               c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('SVM (Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_set_2, Y_set_2 = X_set_1, Y_set_1\n",
    "X1a, X2a = np.meshgrid(np.arange(start = X_set_2[:,0].min() - 1,\n",
    "                               stop = X_set_2[:, 0].max() + 1, step = 0.01),\n",
    "                    np.arange(start = X_set_2[:, 1].min() - 1,\n",
    "                              stop = X_set_2[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1a, X2a, cf.predict(np.array([X1a.ravel(),\n",
    "                                                     X2a.ravel()]).T).reshape(X1a.shape),\n",
    "            alpha = 0.75, cmap = ListedColormap(('red','green')))\n",
    "plt.xlim(X1a.min(), X1a.max())\n",
    "plt.ylim(X2a.min(), X2a.max())\n",
    "for i, j in enumerate(np.unique(Y_set_2)):\n",
    "    plt.scatter(X_set_2[Y_set_2 == j, 0], X_set_2[Y_set_2 == j, 1],\n",
    "               c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('SVM (Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set results of SVM\n",
    "y_preda = cf.predict(X_set_2)\n",
    "y_preda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1 = confusion_matrix(Y_set_2,y_preda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[98, 24],\n",
       "       [55, 73]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive 98\n",
      "False Negative 24\n",
      "False Positive 55\n",
      "True Negative 73\n",
      "Accuracy of classification in svm: 0.684\n"
     ]
    }
   ],
   "source": [
    "true_pos = cm1[0][0]\n",
    "false_neg = cm1[0][1]\n",
    "false_pos = cm1[1][0]\n",
    "true_neg = cm1[1][1]\n",
    "print(\"True Positive {}\".format(true_pos))\n",
    "print(\"False Negative {}\".format(false_neg))\n",
    "print(\"False Positive {}\".format(false_pos))\n",
    "print(\"True Negative {}\".format(true_neg))\n",
    "accuracy = (true_pos+true_neg)/(true_pos+false_neg+false_pos+true_neg)\n",
    "print (\"Accuracy of classification in svm: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
